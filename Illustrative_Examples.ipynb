{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "BZAohYvtTsOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "# specify file path\n",
        "file_folder = \"/drive/MyDrive/Research/metaLLM\"\n",
        "os.chdir(file_folder)"
      ],
      "metadata": {
        "id": "7jNAx3CATuKA",
        "outputId": "05dfa26f-919f-49ef-f66d-61f58ee689d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index"
      ],
      "metadata": {
        "id": "drIknWmmUtZZ",
        "outputId": "5a8cfc09-1211-4c25-ac3a-453df9cdd537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.7 (from llama-index)\n",
            "  Downloading llama_index_core-0.14.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.6.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.13.1)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.28.1)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading llama_index_workflows-2.10.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.32.4)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (4.15.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index) (2.0.0)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.109.1)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index) (3.0.3)\n",
            "Downloading llama_index-0.14.7-py3-none-any.whl (7.4 kB)\n",
            "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.7-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.6-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.10.2-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, setuptools, pypdf, mypy-extensions, marshmallow, colorama, aiosqlite, typing-inspect, griffe, deprecated, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.14.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.7 llama-index-cli-0.5.3 llama-index-core-0.14.7 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.6 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.10.2 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-6.1.3 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0 wrapt-1.17.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "84c19f5c99f548f2ac645b471c46731f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ReAct Agent for a single paper\n",
        "\n",
        "from llama_index.core import (\n",
        "\tSimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_parse import LlamaParse\n",
        "from llama_index.llms.openai import OpenAI"
      ],
      "metadata": {
        "id": "vwbLe_eBVTgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f645bdb-66f4-4685-e95a-2e64cb219d98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /usr/local/lib/python3.12/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1: Optical Character Recognition"
      ],
      "metadata": {
        "id": "VA_GKM8XR0KG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlamaParse"
      ],
      "metadata": {
        "id": "gGn_AK4GV0YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select paper\n",
        "file_names = [file for file in os.listdir(os.path.join(file_folder, 'data/lu_2023'))]\n",
        "print(len(file_names))\n",
        "index_sample = file_names.index(\"Epstein et al_2003_Comparison between two measures of delay discounting in smokers.pdf\")\n",
        "#index_sample = file_names.index(\"Lu et al. - 2022 - Differential Effects of Fundamental and Longitudin.pdf\")\n",
        "file_name = file_names[index_sample]\n",
        "print(file_name)"
      ],
      "metadata": {
        "id": "fv9WY4O_R6Ob",
        "outputId": "103eea1d-621c-44c0-dfc8-6295ceb3994a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "Epstein et al_2003_Comparison between two measures of delay discounting in smokers.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction\n",
        "\n",
        "file_name_path = os.path.join('./data/lu_2023', file_name)\n",
        "\n",
        "parser = LlamaParse(\n",
        "    api_key=\"llx-0UwQzPNaxiYTPoEUuTn0aLCAmORf4upYIRqFWi8tf0zfUWNQ\",  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
        "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
        "    verbose=True,\n",
        ")\n",
        "file_extractor = {\".pdf\": parser}\n",
        "\n",
        "target_paper = SimpleDirectoryReader(\n",
        "    input_files=[file_name_path],\n",
        "    file_extractor=file_extractor,\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "OBtgmbPDUo5E",
        "outputId": "3383dfcf-a5b5-4bfb-b3ed-9596debc372a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id f4894e1a-891b-4e55-a4ad-90b791a43e0b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_paper[4].text)"
      ],
      "metadata": {
        "id": "yQrd7KqDVo1R",
        "outputId": "63c0e398-1ca8-4776-8aaf-bc727844eeb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\n",
            "\n",
            "# AGREEMENT AMONG MEASURES OF DELAY DISCOUNTING\n",
            "\n",
            "# Average Values\n",
            "\n",
            "# Small $25 Rewards\n",
            "\n",
            "| 0  | r = .82, p < .01 | 0                  |\n",
            "| -- | ---------------- | ------------------ |\n",
            "| 20 | 0                | 0                  |\n",
            "| OO | cmeoxo           | (00)               |\n",
            "| 4  | 3                | 2                  |\n",
            "| 0  | 3                | 2                  |\n",
            "| 0  | Log k computer   | Log k computer $25 |\n",
            "\n",
            "# Medium $55 Rewards\n",
            "\n",
            "| r = .76, p < .01   |                    |          |\n",
            "| ------------------ | ------------------ | -------- |\n",
            "| 53                 | 000                | 20       |\n",
            "| O                  | C                  | ((0O)Z)( |\n",
            "|                    | ((x(Z•0)           | 00.00O   |\n",
            "| O                  | R                  | 3        |\n",
            "| 00                 | 5                  |          |\n",
            "| 5                  | 0                  | 5        |\n",
            "| Log k computer $55 | Log k computer $85 |          |\n",
            "\n",
            "# Figure 2\n",
            "\n",
            "Scatterplot of log k values for the computer task and the Kirby questionnaire. The best fitting regression line (solid line) has been fitted to the data. The dashed line is the line of identity. The top left plot shows the best fitting regression line to the k values averaged across the small, medium, and large reward amounts.\n",
            "\n",
            "differences for the small reward, F(1, 77) = 23.72, p &#x3C; .001, within both measures but not within the medium reward, F(1, 77) = 0.50, p > .05, or large reward, F(1, 77) = 0.76, p > .05. The change in k values with increasing reward values was associated with a main effect of reward levels, F(2, 154) = 33.93, p &#x3C; .001, across the two tasks. In addition, there was a significant main effect of task, F(1, 77) = 6.23, p = .02), as the average for the computer task (–2.13) was significantly lower than the average for the Kirby questionnaire (–1.99).\n",
            "\n",
            "# Table 1\n",
            "\n",
            "# Correlation of the Computer Task and the Kirby Questionnaire to Descriptive Variables\n",
            "\n",
            "|                |      |      | Variable | Kirby M | Kirby SD | r    | p    | Computer r | Computer p |\n",
            "| -------------- | ---- | ---- | -------- | ------- | -------- | ---- | ---- | ---------- | ---------- |\n",
            "| Cigarettes/day | 22.0 | 8.2  | .273     | .015    | .234     | .039 |      |            |            |\n",
            "| BMI            | a    | 26.3 | 5.3      | .014    | .903     | .057 | .618 |            |            |\n",
            "| Gender         |      |      | .053     | .648    | .152     | .053 |      |            |            |\n",
            "| Age            | 42.9 | 10.7 | .039     | .736    | .095     | .409 |      |            |            |\n",
            "\n",
            "Note. All the values were converted to z scores before Pearson product–moment correlations were computed, with the exception of values for gender, for which a point–biserial correlation between gender and z log values was determined. BMI = body mass index. an = 32 for men; n = 46 for women.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nougat OCR"
      ],
      "metadata": {
        "id": "Cken5-nmV4MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index llama-index-readers-nougat-ocr==0.3.0"
      ],
      "metadata": {
        "id": "iCGpx4qFV5U7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "72b0af3c-0dcb-4d57-e188-8837c8172900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.7)\n",
            "Collecting llama-index-readers-nougat-ocr==0.3.0\n",
            "  Downloading llama_index_readers_nougat_ocr-0.3.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting nougat-ocr<0.2.0,>=0.1.17 (from llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading nougat_ocr-0.1.17-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.3)\n",
            "INFO: pip is looking at multiple versions of llama-index to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.6-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.5-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.4-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.3-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.2-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.1-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading llama_index-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-index to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_index-0.13.6-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.5-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_index-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.13.0-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading llama_index-0.12.52-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.4-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.5.3-py3-none-any.whl.metadata (441 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.11-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.109.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.13.1)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.28.1)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading llama_index_workflows-1.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.17.3)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "INFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (4.57.1)\n",
            "Collecting timm==0.5.4 (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading timm-0.5.4-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (3.11.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (4.12.0.88)\n",
            "Requirement already satisfied: datasets[vision] in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (4.0.0)\n",
            "Collecting lightning<2022,>=2.0.0 (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting python-Levenshtein (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading python_levenshtein-0.27.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.2.1)\n",
            "Collecting sconf>=0.2.3 (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading sconf-0.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: albumentations>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (2.0.8)\n",
            "Collecting pypdfium2 (from nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.22.0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (1.16.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.0.24)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (4.2.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (6.5.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.8)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.16.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2022,>=2.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning<2022,>=2.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (25.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning<2022,>=2.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-lightning (from lightning<2022,>=2.0.0->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (2.5.0)\n",
            "Collecting ruamel.yaml (from sconf>=0.2.3->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting munch (from sconf>=0.2.3->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.25.1->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.25.1->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.25.1->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.25.1->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.26.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets[vision]->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets[vision]->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets[vision]->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets[vision]->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.70.16)\n",
            "Collecting Levenshtein==0.27.3 (from python-Levenshtein->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-Levenshtein->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.25.1->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (3.4.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-nougat-ocr==0.3.0) (3.0.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->sconf>=0.2.3->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0)\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->timm==0.5.4->nougat-ocr<0.2.0,>=0.1.17->llama-index-readers-nougat-ocr==0.3.0) (1.3.0)\n",
            "Downloading llama_index_readers_nougat_ocr-0.3.0-py3-none-any.whl (2.7 kB)\n",
            "Downloading llama_index-0.12.52-py3-none-any.whl (7.1 kB)\n",
            "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.4-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.52.post1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.8.0-py3-none-any.whl (16 kB)\n",
            "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.5.3-py3-none-any.whl (3.4 kB)\n",
            "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
            "Downloading llama_index_readers_file-0.4.11-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nougat_ocr-0.1.17-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_workflows-1.3.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sconf-0.2.5-py3-none-any.whl (8.8 kB)\n",
            "Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\n",
            "Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, rapidfuzz, pypdfium2, pypdf, munch, lightning-utilities, ruamel.yaml, Levenshtein, sconf, python-Levenshtein, torchmetrics, llama-index-workflows, timm, pytorch-lightning, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, lightning, nougat-ocr, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-nougat-ocr, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 6.1.3\n",
            "    Uninstalling pypdf-6.1.3:\n",
            "      Successfully uninstalled pypdf-6.1.3\n",
            "  Attempting uninstall: llama-index-workflows\n",
            "    Found existing installation: llama-index-workflows 2.10.0\n",
            "    Uninstalling llama-index-workflows-2.10.0:\n",
            "      Successfully uninstalled llama-index-workflows-2.10.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.21\n",
            "    Uninstalling timm-1.0.21:\n",
            "      Successfully uninstalled timm-1.0.21\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.14.7\n",
            "    Uninstalling llama-index-core-0.14.7:\n",
            "      Successfully uninstalled llama-index-core-0.14.7\n",
            "  Attempting uninstall: llama-index-readers-file\n",
            "    Found existing installation: llama-index-readers-file 0.5.4\n",
            "    Uninstalling llama-index-readers-file-0.5.4:\n",
            "      Successfully uninstalled llama-index-readers-file-0.5.4\n",
            "  Attempting uninstall: llama-index-llms-openai\n",
            "    Found existing installation: llama-index-llms-openai 0.6.6\n",
            "    Uninstalling llama-index-llms-openai-0.6.6:\n",
            "      Successfully uninstalled llama-index-llms-openai-0.6.6\n",
            "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
            "    Found existing installation: llama-index-indices-managed-llama-cloud 0.9.4\n",
            "    Uninstalling llama-index-indices-managed-llama-cloud-0.9.4:\n",
            "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.9.4\n",
            "  Attempting uninstall: llama-index-embeddings-openai\n",
            "    Found existing installation: llama-index-embeddings-openai 0.5.1\n",
            "    Uninstalling llama-index-embeddings-openai-0.5.1:\n",
            "      Successfully uninstalled llama-index-embeddings-openai-0.5.1\n",
            "  Attempting uninstall: llama-index-cli\n",
            "    Found existing installation: llama-index-cli 0.5.3\n",
            "    Uninstalling llama-index-cli-0.5.3:\n",
            "      Successfully uninstalled llama-index-cli-0.5.3\n",
            "  Attempting uninstall: llama-index-readers-llama-parse\n",
            "    Found existing installation: llama-index-readers-llama-parse 0.5.1\n",
            "    Uninstalling llama-index-readers-llama-parse-0.5.1:\n",
            "      Successfully uninstalled llama-index-readers-llama-parse-0.5.1\n",
            "  Attempting uninstall: llama-index\n",
            "    Found existing installation: llama-index 0.14.7\n",
            "    Uninstalling llama-index-0.14.7:\n",
            "      Successfully uninstalled llama-index-0.14.7\n",
            "Successfully installed Levenshtein-0.27.3 lightning-2.5.5 lightning-utilities-0.15.2 llama-index-0.12.52 llama-index-agent-openai-0.4.12 llama-index-cli-0.4.4 llama-index-core-0.12.52.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.8.0 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.3 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.11 llama-index-readers-llama-parse-0.4.0 llama-index-readers-nougat-ocr-0.3.0 llama-index-workflows-1.3.0 munch-4.0.0 nougat-ocr-0.1.17 pypdf-5.9.0 pypdfium2-5.0.0 python-Levenshtein-0.27.3 pytorch-lightning-2.5.5 rapidfuzz-3.14.3 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 sconf-0.2.5 timm-0.5.4 torchmetrics-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index",
                  "workflows"
                ]
              },
              "id": "505c32ae9f8d4bc981d621a606432618"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.38.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vtbyG7QrYa2K",
        "outputId": "44cf09a6-4d8c-45bb-a2bf-94e7dd859fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.38.2\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2.32.4)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (2025.10.5)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"albumentations<1.3.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbWLg1CwYcxN",
        "outputId": "66ccde25-6cd6-4cac-e15b-430f84f2f611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations<1.3.0\n",
            "  Downloading albumentations-1.2.1-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from albumentations<1.3.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from albumentations<1.3.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.12/dist-packages (from albumentations<1.3.0) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations<1.3.0) (6.0.3)\n",
            "Collecting qudida>=0.0.4 (from albumentations<1.3.0)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from albumentations<1.3.0) (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from qudida>=0.0.4->albumentations<1.3.0) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qudida>=0.0.4->albumentations<1.3.0) (4.15.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations<1.3.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<1.3.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<1.3.0) (3.6.0)\n",
            "Downloading albumentations-1.2.1-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "Successfully installed albumentations-1.2.1 qudida-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.nougat_ocr import PDFNougatOCR\n",
        "from pathlib import Path\n",
        "reader = PDFNougatOCR()\n",
        "pdf_path = Path(os.path.join('./data/lu_2023', file_name))\n",
        "\n",
        "documents = reader.load_data(pdf_path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gMaVOsNeXyTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_documents = \"/n\".join([doc.text for doc in documents])"
      ],
      "metadata": {
        "id": "Kq6FT1-dYW0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FP4djh32YzsB",
        "outputId": "80560b3f-3baa-4f7f-f9ca-5ac020c051d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Comparison Between Two Measures of Delay Discounting in Smokers\n",
            "\n",
            "Leonard H. Epstein, Jerry B. Richards,\n",
            "\n",
            "Frances G. Saad, Rocco A. Paluch, and\n",
            "\n",
            "James N. Roemmich\n",
            "\n",
            "University at Buffalo School of Medicine and Biomedical Sciences, University at Buffalo, State University of New York, Farber Hall, Room G56, 3435 Main Street, Building #26, Buffalo, New York 14214-3000. E-mail: lhenet@acsu.buffalo.edu\n",
            "\n",
            "Caryn Lerman\n",
            "\n",
            "University of Pennsylvania School of Medicine\n",
            "\n",
            "###### Abstract\n",
            "\n",
            "Agreement between computer and questionnaire measures of delay discounting in smokers was compared. Correlations between measures for small, medium, or large rewards were significant. Log $k$ values decreased as the reward delay increased, with values lower for the computer task than the questionnaire, with significant differences for small rewards. The 2 measures were related to smoking rate but not to age, gender, or obesity. The Bland-Altman test of agreement indicated large within-subject differences in $k$ values between the 2 measures. The size of the difference between the log $k$ values and magnitude of the log $k$ values were positively related. Results suggest $k$ values from the 2 measures are related but may not be used interchangeably.\n",
            "\n",
            "One important component of self-regulation is the delay of immediate gratification to obtain later but larger rewards (Logue & King, 1991). When provided a choice between a small immediate reward and larger delayed rewards, people reliably discount the value of the larger delayed rewards (Bickel, Madden, & Petry, 1998; Richards, Zhang, Mitchell, & de Wit, 1999). _Delay discounting_ has been used as an operational definition of impulsivity. The degree to which individuals discount the value of delayed consequences has been suggested to be an index of impulsivity, with greater discounting indicating greater impulsivity (Ainslie, 1975; Logue, 1988; Rachlin & Green, 1972; Richards et al., 1999). According to this definition of impulsivity, the behavior of individuals who discount the value of delayed consequences at a high rate is likely to be biased toward immediate consequences over more important delayed consequences. For example, cigarette smokers may choose the immediate effects of smoking over the delayed risk of emphysema and cancer. There is a growing body of evidence that individuals that engage in impulsive behaviors discount the value of delayed rewards more in laboratory tasks (Bickel & Marsch, 2001; Critchfield & Kollins, 2001). For example, several studies with drug-dependent individuals have shown that drug users discount the value of delayed rewards more than nondrug users. This has been reported for opioid-dependent individuals (Kirby, Petry, & Bickel, 1999; Madden, Petry, Badger, & Bickel, 1997), alcohol abusers (Vuchinich & Simpson, 1998), cigarette smokers (Bickel, Odum, & Madden, 1999; Mitchell, 1999), and individuals with unspecified histories of drug dependence (Allen, Moeller, Rhoades, & Cherek, 1998). These results indicate that there are large individual differences in delay discounting and that delay discounting may be a valid model of impulsive behavior in humans.\n",
            "\n",
            "The most commonly used procedure to measure discounting (Rachlin, Rainieri, & Cross, 1991) determines the value of delayed rewards by presenting the participant with two cards--the amount of the delayed reward (e.g., S100 in 1 year) is on one card and the amount of an immediate reward is on the second card (e.g., S25 right now). The participants are presented with an ascending sequence of immediate amount cards starting at a low amount and asked whether they prefer the immediate or the delayed reward. The point at which they switch from the delayed to the immediate amount is used to determine an indifference point that indicates how much they value the delayed reward. The same procedure is usually repeated for each delayed reward using a descending sequence to firmly establish the indifference point. A variant on this procedure is to use a computer to present the questions in a random order (Mitchell, 1999) to avoid possible order effects of asking the questions in a strict ascending or descending order.\n",
            "\n",
            "In an attempt to decrease the number of questions required to determine indifference points, we developed a computer-based adjusting-amount (AA) procedure that adjusts the amount of the immediate alternative to determine indifference points (Richards et al., 1999). The computer generates the questions on the basis of the participant's answers to the preceding questions about preference of immediate versus delayed rewards, which allows the AA procedure to more rapidly determine indifference points. We have used this AA procedure to evaluate the influence of alcohol on discounting (Richards et al., 1999) and have shown that psychiatric patients with disorders related toimpulse control discount at different rates than patients who do not have disorders of impulse control (Crean, de Wit, & Richards, 2000). The average duration for determining 15 indifference points (5 indifference points for each of three reward values) for an individual participant using the AA procedure is 15 min, but this can vary as a function of the consistency of the participant's responding. If the participant is not consistent, then additional questions are asked until a consistent pattern emerges.\n",
            "\n",
            "Kirby and colleagues (Kirby et al., 1999; Kirby & Marakovic, 1996) developed a questionnaire that samples 27 immediate versus delayed choices and takes about 5 min to complete. The Kirby questionnaire is much faster and easier to administer than the card- or computer-based procedures described above. The questionnaire provides a simple methodology for obtaining estimates of delay discounting, but, to our knowledge, this methodology has not been compared with more detailed methods for measuring discounting tasks such as the AA task.\n",
            "\n",
            "The purpose of this study was to compare the relationship and agreement between the AA discounting task and the Kirby questionnaire for assessing discounting of monetary rewards. One approach to comparing the two measures was to calculate the correlation coefficient. Despite the common use of correlations as measures of agreement between measures, there are limitations to use of correlations for this purpose (Bland & Altman, 1986, 1995). For example, one measure may provide twice the value of the other, and if it does this reliably, the measures would show strong correlations, but the absolute values of the measures would not agree. Alternatively, the measures may differ in agreement at points along the continuum being measured.\n",
            "\n",
            "It is also possible for measures to be correlated but have inconsistent relationships with important criterion variables. For example, we have shown that self-report and objectively measured physical activity are moderately related, but each of these measures of physical activity are significantly related to different sets of correlates (Epstein, Paluch, Coleman, Vito, & Anderson, 1996). In assessing the relationship between two measures, it is important to show not only the correspondence between the measures but also their association to other measures. If the measures are assessing the same construct, then the measures should be related in the same way to other variables.\n",
            "\n",
            "Another way to test the agreement between estimates of delay discounting is to compare discounting of small, medium, and large rewards. Previous studies have shown that small rewards are discounted at a higher rate than large rewards (Green, Myerson, & McFadden, 1997; Kirby & Marakovic, 1996). Differential effects of reward amount on the rate of discounting as measured by the two procedures would provide information about the sensitivity of the two procedures. If there is no significant difference between the estimates of discounting for large, medium, and small amounts, and the two tasks are significantly related to each other and share similar relationships to other variables, there is greater confidence that they are measuring similar constructs.\n",
            "\n",
            "Agreement between the measures can also be studied using the Bland-Altman pairwise comparison approach (Bland & Altman, 1986, 1995). This approach is designed to assess the extent to which two measures agree and are interchangeable. The Bland-Altman method calculates the average difference between the two measures and the standard deviation of this difference--the smaller the standard deviations of the difference scores, the better the agreement. The Bland-Altman analysis also identifies whether there is a relationship between the magnitude of the variables and the degree of discrepancy between the measures.\n",
            "\n",
            "Method\n",
            "\n",
            "### Participants\n",
            "\n",
            "Participants were 32 male and 46 female smokers age 18 years and over. The average participant was 42.9 $\\pm$ 10.6 years of age, smoked 21.9 $\\pm$ 8.1 cigarettes per day, and had a mean body mass index (BMI = kg/m${}^{2}$) of 26.2 $\\pm$ 5.2. The ethnic distribution in the study was 90% Caucasian, 9% African American, and 1% Hispanic. Thirty-two type of participants completed high school or less; the remaining 68% completed some college or technical school or beyond. Smokers were recruited through newspaper advertisements, brochures, flyers, and local media inviting them to participate in a smoking cessation program. Participants were excluded if they met any of the following criteria: smoked fewer than 10 cigarettes a day during the past year; had uncontrolled heart disease; were planning a pregnancy; were pregnant; were lactating; had a seizure disorder; had a history of head trauma or prior seizure; had a brain or central nervous system tumor; had a history of or were currently diagnosed with bulimira or anorexia nervosa; had diabetes; used alcohol excessively; had a current addiction to opiates, cocaine, or stimulants; had current depression or mania; were using chewing tobacco or snuff; or had an Axis I major psychiatric disorder. At the initial screening session, smokers were offered the opportunity to participate in a supplemental study to collect delay-discounting measures.\n",
            "\n",
            "### Design and Procedure\n",
            "\n",
            "At the initial visit participants completed standard questionnaires assessing demographics of age, gender, smoking history, and number of cigarettes smoked per day (Lerman et al., 1997). Height and weight were taken to calculate BMI. After collection of this information, participants completed the two delay-discounting measures, presented in a random order across participants.\n",
            "\n",
            "The monetary-choice questionnaire developed by Kirby et al. (1999) included a fixed set of 27 choices between smaller immediate rewards and larger delayed rewards. An example choice is \"Would you prefer S55 today or S75 in 61 days?\" Participants indicated which alternative they would prefer by circling one alternative for each item of the questionnaire. The range of delays included in the Kirby questionnaire was 7 to 186 days. The questionnaire is a sensitive measure of discounting--discriminating discount rates of drug users and nonusers (Kirby et al., 1999; Madden et al., 1997). The Kirby delay-discounting questionnaire was scored using the procedures described by Kirby and colleagues (Kirby et al., 1999). The $k$ values provided by the Kirby questionnaire have a range of 10 discrete steps: 00016, 00025,.00063,.0016,.0039,.010,.0126,.065,.16, and.25. Each participant was assigned one of these $k$ values on the basis of his or her answers to the 27 items. The Kirby questionnaire provided $k$ values for high ($85, $80, $75), medium ($60, $55, $50), and low ($35, $30, $25) value delayed rewards. Previous research using this procedure (Kirby et al., 1999) showed high value monetary rewards were discounted less than lower value monetary rewards.\n",
            "\n",
            " Participants also completed a computerized AA choice procedure to assess discounting of delayed reinforcers (Richards et al., 1999). This procedure has been shown to discriminate between psychiatric outpatients with and without a history of impulsive behavior (Crean et al., 2000). Participants were presented with an average of 110 questions. The exact number of questions was determined by the computer test procedure and by how consistently the participants answered the questions. Participants chose between amounts of money available after different delays and amounts of money available immediately. The amount of immediate money was adjusted (by the computer) to determine the point at which the participants were indifferent about the immediate and delayed amounts.\n",
            "\n",
            "The time delays of the monetary rewards consisted of $\\lx@sectionsign$2, 30, 180, 365, or 730 days. Discount functions for the different amounts of delayed money ($\\lx@sectionsign$85, $\\lx@sectionsign$55, $\\lx@sectionsign$25) were determined. An example question is \"Which would you prefer, $\\lx@sectionsign$65 today or $\\lx@sectionsign$85 two days from now?\" Participants used the computer mouse to indicate which reward they would prefer. The AA procedure used the answers to previous questions to narrow the range of values from which the value for the next question was selected. This reduced the number of questions needed to estimate the indifference points for the delay and probability discount functions for an individual compared with standard ascending-descending procedures (Rachlin et al., 1991). The amount of immediate money the participant judged to be equivalent to the delayed reward was taken to indicate the subjective value of the delayed rewards. These points of subjective equality were called indifference points. The adjusting nature of the task was masked by not using a predictable algorithm for determining the adjusted value for the subsequent questions. The algorithm used by the AA procedure is described in detail in Richards et al., 1999.\n",
            "\n",
            "Discounting of reward value as a function of delay (Green, Fry, & Myerson, 1994) is described by a hyperbolic discount function (Mazur, 1987). The formula used to determine this value is as follows: $\\text{Value}=\\text{A/}(1+k\\text{D})$, where \"A\" represents the amount of the delayed reward, \"D\" represents the delay, and $k$ represents a free parameter. Indifference points were determined for the five different delays--2, 30, 180, 365, and 730 days--using the AA procedure. The hyperbolic discount equation was then fit to indifference points using a nonlinear curve-fitting program (Origin 6.0, Microlal Software, Inc., Northampton, MA) to determine the value of $k$. In addition to the $k$ values, the curve-fitting procedure provided goodness-of-fit measures, chi-square, and the coefficient of determinations ($r^{2}$). Outlying $k$ values that were greater than 1.0 or had $r^{2}$ values less than 0.4 were not included in the analysis.\n",
            "\n",
            "The log of the $k$ values for the three different delayed amounts were used to normalize the distribution of $k$ values for the computer task. Deviations from normality were determined by calculating skewness statistics and their standard errors. Distributions that have skewness/S.E. skewness values that are greater than 1.96 are considered not to be normally distributed. Before log transformations, the skewness/S.E. skewness values for small, medium, and large rewards were 15.7, 17.7, and 13.6, respectively, for the computer task, and 14.1, 15.8, and 15.5, respectively, for the Kirby questionnaire. Log transformations reduced the values for small, medium, and large rewards to 0.97, 1.36, and 1.64, respectively, for the computer task, and 2.56, 0.64, and 0.51, respectively, for the Kirby questionnaire. Thus, log transformations drastically reduced skewness for every measure, and with the exception of small rewards for the Kirby questionnaire, the distributions did not deviate from normality after log transformation. The means and standard deviations of the log values for the Kirby questionnaire across the three reward values were -1.87 $\\pm$ 0.55, -2.10 $\\pm$ 0.59, and -2.18 $\\pm$ 0.62, whereas values for the AA procedures for the three reward values were -2.12 $\\pm$ 0.68, -2.14 $\\pm$ 0.75, and -2.23 $\\pm$ 0.75. The log of the $k$ value was used for all analyses.\n",
            "\n",
            "Participants were given a one-in-six chance of receiving the reward that they chose on one of the tasks to encourage accurate responding (Griffiths, Rush, & Puhala, 1996). At the end of the session, participants selected a ball from a bingo device that corresponded to choice made on one of each task. If participants rolled a 6 on a dice they received the reward they chose.\n",
            "\n",
            "One important consideration in comparing the two tasks was the difference in delay between the two tasks. The Kirby questionnaire has delays up to 186 days, whereas the computer task has delays up to 730 days. Because the computer task also includes a 180-day delay, we compared log $k$ values for the computer task using all the delays and delays up to 180 days. The log $k$ values were very similar, with correlations between measures using all the delays and those using only delays up to 180 days of.94,.93, and.92, respectively, for small, medium, and large rewards. In addition, a within-subjects analysis of variance (ANOVA) was used to compare the log $k$ values between the two sets of delays (all the delays vs. delays up to 180 days) as one within-variable and reward value ($\\lx@sectionsign$25, $\\lx@sectionsign$55, $\\lx@sectionsign$85) as the second within-variable. The analysis showed a significant difference between reward values, $F(2,\\,148)=6.01$, $p<.01$, but there were no differences ($p>.10$) as a function of length of delay or the interaction of Length of Delay $\\times$ Reward Value. The means and standard deviations for the full range of delays across the three reward values ($\\lx@sectionsign$25, $\\lx@sectionsign$55, $\\lx@sectionsign$85) were -2.12 $\\pm$ 0.68, -2.14 $\\pm$ 0.75, -2.23 $\\pm$ 0.75, whereas the corresponding means and standard deviations for delays up to 180 days were -2.05 $\\pm$ 0.65, -2.09 $\\pm$ 0.73, -2.19 $\\pm$ 0.74. Because the values were very similar, we used the $k$ values for the longer delay, as these were based on more data points (five delays vs. three delays) and provided a more stable estimate of $k$ values.\n",
            "\n",
            "### Analytic Plan\n",
            "\n",
            "The Pearson product-moment correlation coefficient between the two measures was calculated, as was the correlation between the average $k$ values on each task and cigarettes per day, education, BMI, gender, and age. To ensure that the correlations were performed on variables that were scaled similarly, variables were converted to $z$ scores prior to correlations being performed. A repeated measures ANOVA, with Task as one within-factor and Amount (small, medium, large) as the second within-factor, was used to determine whether the $k$ values obtained from the two tasks were significantly different.\n",
            "\n",
            "The Bland-Altman analysis also was completed to compare (Bland & Altman, 1986, 1995) agreement between the two measures. This procedure calculates the difference between the log $k$ values for the two measures (computer task - Kirby questionnaire) and the average of the log $k$ values of the two measures ((computer task $+$ Kirby questionnaire)/2) for each participant. These data were graphed, and the correlation and slope based on the regression model between the difference of the two measures and the average log $k$ were calculated. The first indicator of agreement is the average of the difference scores. Ideally, this difference would be 0. The second indicator of agreement is the variability of the discrepancy scores. The Bland-Altman analysis uses the difference between 2 standard deviations from the mean difference as an indicator of within-subject discrepancy. The larger these limits of agreement, the greater the within-subject discrepancy. The third indicator of agreement establishes the regression between the difference score and the average of the two log $k$ values to determine whether the degree of discrepancy reliably changes as a function of the size of $k$.\n",
            "\n",
            "## Results\n",
            "\n",
            "Figure 1 shows the best-fitting hyperbolic discount function to the median of the $k$ values for the three reward values of the AA task. As shown by the plots in Figure 1, the indifference points obtained by the AA task were well described by the hyperbolic discount function at each reward value. The mean $r^{2}$ values for all participants for the small, medium, and large rewards were.83,.84,.85, respectively. There is no curve fit for the Kirby questionnaire because it is based on the assumption that the hyperbolic discount equation describes each individual's choices on the questionnaire. Thus, there is no way to assess goodness of fit or how well the assumption of hyperbolic discounting describes each individual's answers to the questions on the Kirby questionnaire.\n",
            "\n",
            "The average $k$ values for the AA task and the Kirby questionnaire were strongly correlated ($r=.82$, $p<.001$), as were the correlations for small, medium, and large amounts ($r$s =.74$-$.80, $p$s $<.001$). These values, with the best-fitting regression between the two, are shown in Figure 2. There are positive slopes of.62,.60,.60, and.66 for the average, small, medium, and large values, respectively, suggesting that the Kirby questionnaire shows an increase of.60 to.66 log $k$ values for every 1.0 increase in the AA computer task log $k$ value.\n",
            "\n",
            "Correlations between the AA task and Kirby questionnaire and cigarettes per day, BMI, gender, and age are shown in Table 1. The degree of relationship between each measure of discounting and the predictors were similar. For example, more cigarettes smoked per day predicted higher impulsivity scores on the AA task ($r=.23$, $p<.05$) and on the Kirby questionnaire ($r=.27$, $p<.025$). BMI, gender, and age did not correlate with either measure. Gender was marginally related to average $k$ values on the AA task ($p=.053$), although it was not close to being significant ($p=.65$) for the Kirby questionnaire.\n",
            "\n",
            "The comparison of the log $k$ values between the two tasks showed there was a significant interaction between task and reward value, $F(2,\\,154)=12.56$, $p<.001$, as the degree of discounting decreased for the computer task from small to medium to large rewards from -1.94 to -2.14 to -2.23, respectively, whereas questionnaire values for small to medium to large rewards changed from -1.87 to -2.10 to -2.18, respectively. Post hoc linear mean comparisons at each level of reward revealed that there were significant\n",
            "\n",
            "Figure 1: The best fitting hyperbolic discount functions to the median of the $k$ values for small, medium, or large reward values for the computer task. The top left plot shows the best fitting hyperbolic discount functions for the small, medium, and large rewards on the same graph, with the monetary reward values proportional, whereas the other graphs show the hyperbolic functions for the monetary reward values used.\n",
            "\n",
            "differences for the small reward, $F(1,\\,77)=23.72$, $p<.001$, within both measures but not within the medium reward, $F(1,\\,77)=0.50$, $p>.05$, or large reward, $F(1,\\,77)=0\\,.76$, $p>.05$. The change in $k$ values with increasing reward values was associated with a main effect of reward levels, $F(2,\\,154)=33.93$, $p<.001$, across the two tasks. In addition, there was a significant main effect of task, $F(1,\\,77)=6.23$, $p<.02$), as the average for the computer task (-2.13) was significantly lower than the average for the Kirby questionnaire (-1.99).\n",
            "\n",
            "Finally, Bland-Altman plots for average, small, medium, and large amounts are shown in Figure 3. This figure shows that the average discrepancy is -14, -25, -04, and -05 for the average, small, medium, and large amounts, respectively. Thus, the discrepancy between the two measures is greater for small rewards, as shown above in the ANOVA. The range of values encompassed by 2 standard deviations of the discrepancy scores is also shown in Figure 3. The 2 standard deviation limits of agreement were.683 to -.969,.662 to -1.166, 0.935 to -1.013, and.869 to -.959 for the average, small, medium, and large amounts, respectively. The limits of agreement indicate that the range of variation in the discrepancy scores covered by 2 standard deviations from the mean was 40% to 50% of the value of the mean\n",
            "\n",
            "\\begin{table}\n",
            "\\begin{tabular}{l c c c c c c} \\hline \\hline \\multicolumn{1}{c}{} & & & \\multicolumn{2}{c}{Kirby} & \\multicolumn{2}{c}{Computer} \\\\ \\cline{3-6} \\multicolumn{1}{c}{Variable} & $M$ & $SD$ & $r$ & $p$ & $r$ & $p$ \\\\ \\hline Cigarettes/day & 22.0 & 8.2 &.273 &.015 &.234 &.039 \\\\ BMI & 26.3 & 5.3 & -014 &.903 & -057 &.618 \\\\ Gender${}^{\\text{a}}$ & & 053 &.648 &.152 &.053 \\\\ Age & 42.9 & 10.7 & ($-$0.39) &.736 & $-$0.95 &.409 \\\\ \\hline \\hline \\end{tabular} Note. All the values were converted to $z$ scores before Pearson product-moment correlations were computed, with the exception of values for gender, for which a point-biserial correlation between gender and $z$ log values was determined. BMI = body mass index. ${}^{\\text{a}}n=32$ for men; $n=46$ for women.\n",
            "\n",
            "\\end{table}\n",
            "Table 1: Correlation of the Computer Task and the Kirby Questionnaire to Descriptive Variables\n",
            "\n",
            "Figure 2: Scatterplot of log $k$ values for the computer task and the Kirby questionnaire. The best fitting regression line (solid line) has been fitted to the data. The dashed line is the line of identity. The top left plot shows the best fitting regression line to the $k$ values averaged across the small, medium, and large reward amounts.\n",
            "\n",
            "value. For example, in the case of the $k$ values for the medium reward amount, 2 standard deviations of the discrepancy scores divided by the mean of the two methods for measuring the $k$ value was 0.46. These results show that there were substantial differences in the values of $k$ assigned to the same participant by the two methods for measuring $k$. The plots in Figure 3 indicate there are significant positive correlations for average, small, medium, and large amounts ($r$s $=$.45,.30,.35, and.31, respectively; $p$s $<$.01). The positive slopes (0.31, 0.24, 0.27 0.21) associated with these correlations indicate that for each amount of reward, as the values of the measures increased, the discrepancy between the two measures also increased.\n",
            "\n",
            "The Kirby questionnaire was designed to sample choices that were representative of a range of $k$ values from.00016 to.25. In the current study no participant had lower discounting values than.00016, and only 2 participants had higher discounting values than 0.25 in the computer task. If the Bland-Altman analysis is done without these 2 participants, the mean discrepancy is decreased from - 0.143 to $-$0.177 $k$ values, and the standard deviation is reduced from 0.413 to 0.361 $k$ values. The range of scores that capture 2 standard deviations of the measures shifts from - 0.969 to 0.683 for all participants to - 0.899 to 0.545 for participants who scored inside of the Kirby questionnaire range. The relationship between mean discrepancy and magnitude of average $k$ decreased from 0.45 to 0.36 (both $p$s $<$.01), and slope of the regression line decreased from 0.31 to 0.22. Thus, even without these 2 participants there is a considerable discrepancy, and the degree of discrepancy is still positively associated with magnitude of discounting.\n",
            "\n",
            "## 7 Discussion\n",
            "\n",
            "The results of this study show that the AA procedure and the Kirby questionnaire are strongly related for the average discounting values and discounting at each of three reward amounts in smokers. Likewise, the AA procedure and the Kirby questionnaire correlate similarly with other variables,\n",
            "\n",
            "Figure 3: Bland–Altman plots for the difference between the log $k$ values for the computer task and the Kirby questionnaire versus the magnitude of the log $k$ values for the average, small, medium, and large rewards. The 2 standard deviations of the differences are shown to provide an indication of the variability in difference scores. The short dashed line indicates the mean difference between methods, the solid lines indicate 2 standard deviation limits of agreement, the long dashed line indicates relationship between difference scores and average magnitude of the scores. See text for a detailed description.\n",
            "\n",
            "such as cigarettes smoked and education. The degree of correspondence between the two measures indicates that both procedures were measuring similar choice processes.\n",
            "\n",
            "Comparison of $k$ values across both tasks showed decreases in discounting as the reward value of the delayed alternative increases and showed that the Kirby questionnaire produces greater levels of overall discounting than the AA procedure. The difference was greatest in comparing $k$ values for small rewards. One possible explanation for the difference between the methods was that participants may have discounting values that are outside the range of the 10 Kirby $k$ values ranging from.00016 to.25. Removing the 2 participants who scored outside the range of $k$ scores that the Kirby measures did not appreciably change the variability or the pattern of discrepancy. A second possibility is that the Kirby questionnaire is less sensitive than the AA procedure (particularly at larger values of _k_) because it provides only 10 discrete $k$ values, whereas the AA procedure provides a continuous measure of $k$. The difference between the 10 discrete estimates of $k$ provided by the Kirby questionnaire increases logarithmically as the value of $k$ increases, so there is a larger distance between possible discrete $k$ values in the Kirby questionnaire at the larger values of $k$.\n",
            "\n",
            "The Bland-Altman (Bland & Altman, 1986, 1995) plots showed the limits of agreement, as measured by 2 standard deviations for the discrepancy, between the measures was large. There was a pattern in the comparison of the discrepancy between the two measures, with the Kirby questionnaire scoring lower than the AA procedure when the $k$ values were low and the Kirby questionnaire scoring greater when the $k$ values were greater. These results suggest that the measures may not be interchangeable across all levels of $k$ values.\n",
            "\n",
            "An investigator could draw different conclusions from the results of the standard correlational techniques, which demonstrated that the measures were strongly correlated (_r_s of.74 to.82), and that of the Bland-Altman tests of agreement. As discussed by Bland and Altman (Bland & Altman, 1986), the discrepancy in the outcomes of the correlational and Bland-Altman analyses is because correlational analyses test the strength of the relationship between two measures but not the agreement between two measures. A high correlation can exist between scores if the scores lie along the same line, even if the scale of one axis is twofold the other axis. There is agreement only if the scores lie along the line of identity, which has a slope of 1.0. As shown in Figure 2, the relationship between the Kirby questionnaire and the AA procedure has a slope of approximately 0.6 rather than 1.0 and, therefore, the points do not lie along the line of identity. Thus, as shown in the present data, a high correlation between two sets of measurement data does not mean that there is agreement between the two measures. Because there is no \"gold standard\" for measuring the value of $k$, it is not possible to determine which measure is the most accurate measure of discounting. The usefulness of each measure depends on the situation in which it is used.\n",
            "\n",
            "The Kirby questionnaire provides a very efficient method for obtaining estimates of discounting, whereas the AA procedure may provide a more sensitive measure of discounting. An advantage of the Kirby questionnaire is the opportunity to collect discounting data on large samples of participants at very little time and cost, which may be very useful in field and epidemiological studies. The questionnaire may be particularly useful when the emphasis is not on individual change but rather on characterizing trends in particular samples. There are many situations in which a detailed measure of discounting is needed, and a measure in which standard diagnostics for evaluating the fit of the hyperbolic discount function are needed. In these cases the preferred method is the computer-based AA procedure.\n",
            "\n",
            "There are several design considerations that might influence the interpretation of the results. The questionnaire and computer task provide alternative formats to determine delay discounting, with the questionnaire involving a paper-and-pencil response format and the computer task involving responding on a computer keyboard. Although the questions that are asked of the participant are very similar, it is possible that some of the differences in $k$ values between the tasks are due to differences in response formats. This study attempted to reduce any potential limitations of using hypothetical rewards by having participants receive immediate or delayed rewards on a probabilistic basis, such that participants had a one-in-six chance of receiving one of their choices. Recent research (Johnson & Bickel, 2002) has shown that similar discounting functions are obtained when using hypothetical or real rewards, making it easier to implement future studies comparing different methods of measuring delay discounting by using only hypothetical rewards. Finally, all the participants in this study were smokers, who have been shown to be more impulsive on delay discounting measures than nonsmokers (Bickel et al., 1999; Mitchell, 1999). It is possible that a different relationship between measures would be obtained if a different population was studied.\n",
            "\n",
            "There are alternatives to the Kirby and AA procedures for measuring discounting in the laboratory. The most common method for measuring discounting is to ask a prescribed set of questions about every possible combination of delay and reward. These procedures usually systematically increase or decrease the immediate amount (Rachlin et al., 1991), although procedures that randomize the questions have also been used (Mitchell, 1999). There is no gold standard for measurement of delay discounting, and as research in delay discounting and impulsivity matures, identification of sensitive and psychometrically sound measures are needed to provide comparability of major findings across studies. Future researchers may want to study the agreement between alternative laboratory methods to assess discounting to provide information needed to establish a standard measure of discounting.\n",
            "\n",
            "## References\n",
            "\n",
            "* [Ainslie (1975)] Ainslie, G. (1975). Specious reward: A behavioral theory of impulsiveness and impulse control. _Psychological Bulletin, 82_, 463-496.\n",
            "* [Allen et al. (1998)] Allen, T. J., Moeller, F. G., Rhoades, H. M., & Cherek, D. R. (1998). Impulsivity and history of drug dependence. _Drug and Alcohol Dependence, 50_, 137-145.\n",
            "\n",
            "Bickel, W. K., Madden, G. J., & Petry, N. M. (1998). The price of change: The behavioral economics of drug dependence. _Behavior Therapy_, _29_, 545-565.\n",
            "* Bickel & Marsch (2001) Bickel, W. K., & Marsch, L. A. (2001). Toward a behavioral economic understanding of drug dependence: Delay discounting processes. _Addiction_, _96_, 73-86.\n",
            "* Bickel et al. (1999) Bickel, W. K., Odum, A. L., & Madden, G. J. (1999). Impulsivity and cigarette smoking: Delay discounting in current, never, and ex-smokers. _Psychopharmacology_, _146_, 447-454.\n",
            "* Bland & Altman (1986) Bland, J. M., & Altman, D. G. (1986). Statistical methods for assessing agreement between two methods of clinical measurement. _Lancet_, $1$, 307-310.\n",
            "* Bland & Altman (1995) Bland, J. M., & Altman, D. G. (1995). Comparing methods of measurement: Why plotting difference against standard method is misleading. _Lancet_, _346_, 1085-1087.\n",
            "* Creen et al. (2000) Creen, J. P., de Wit, H., & Richards, J. B. (2000). Reward discounting as a measure of impulsive behavior in a psychiatric outpatient population. _Experimental and Clinical Psychopharmacology_, $8$, 155-162.\n",
            "* Critchfield & Kollins (2001) Critchfield, T. S., & Kollins, S. H. (2001). Temporal discounting: Basic research and the analysis of socially important behavior. _Journal of Applied Behavior Analysis_, _34_, 101-122.\n",
            "* Epstein et al. (1996) Epstein, L. H., Paluch, R. A., Coleman, K. J., Vito, D., & Anderson, K. (1996). Determinants of physical activity in obese children assessed by accelerometer and self-report. _Medicine & Science in Sports & Exercise_, _28_, 1157-1164.\n",
            "* Green et al. (1994) Green, L., Fry, A. F., & Myerson, J. (1994). Discounting of delayed rewards: A life-span comparison. _Psychological Science_, $5$, 33-36.\n",
            "* Green et al. (1997) Green, L., Myerson, J., & McFadden, E. (1997). Rate of temporal discounting decreases with amount of reward. _Memory and Cognition_, _25_, 715-723.\n",
            "* Griffiths et al. (1996) Griffiths, R. R., Rush, C. R., & Puhala, K. A. (1996). Validation of the multiple-choice procedure for investigating drug reinforcement in humans. _Experimental and Clinical Psychopharmacology_, $4$, 97-106.\n",
            "* Johnson & Bickel (2002) Johnson, M. W., & Bickel, W. K. (2002). Within-subject comparison of real and hypothetical money rewards in delay discounting. _Journal of the Experimental Analysis of Behavior_, _77_, 129-146.\n",
            "* Kirby & Marakovic (1996) Kirby, K. N., & Marakovic, N. N. (1996). Delay-discounting probabilistic rewards: Rates decrease as amounts increase. _Psychonomic Bulletin & Review_, $3$, 100-104.\n",
            "* Kirby et al. (1999) Kirby, K. N., Petry, N. M., & Bickel, W. K. (1999). Heroin addicts have higher discount rates for delayed rewards than non-drug-using controls. _Journal of Experimental Psychology: General_, _128_, 78-87.\n",
            "* Lerman et al. (1997) Lerman, C., Gold, K., Audrain, J., Lin, T. H., Boyd, N. R., Orleans, C. T., et al. (1997). Incorporating biomarkers of exposure and genetic susceptibility into smoking cessation treatment: Effects on smoking-related cognitions, emotions, and behavior change. _Health Psychology_, _16_, 87-99.\n",
            "* Logue (1988) Logue, A. W. (1988). Research on self-control: An integrating framework. _Behavioral and Brain Sciences_, _11_, 665-709.\n",
            "* Logue & King (1991) Logue, A. W., & King, G. R. (1991). Self-control and impulsiveness in adult humans when food is a reinforcer. _Aptetite_, _17_, 105-120.\n",
            "* Madden et al. (1997) Madden, G. J., Petry, N. M., Badger, G. J., & Bickel, W. K. (1997). Impulsive and self-control choices in opioid-dependent patients and non-drug-using control participants: Drug and monetary rewards. _Experimental and Clinical Psychopharmacology_, $5$, 256-262.\n",
            "* Mazur (1987) Mazur, J. E. (1987). An adjusting procedure for studying delayed reinforcement. In M. L. Commons, J. E. Mazur, J. A. Nevin, & H. Rachlin (Eds.), _Quantitative analyses of behavior: The effect of delay and of intervening events on reinforcement value_ (Vol. 5, pp. 55-73). Hillsdale, NJ: Erlbaum.\n",
            "* Mitchell (1999) Mitchell, S. H. (1999). Measures of impulsivity in cigarette smokers and non-smokers. _Psychopharmacology_, _146_, 455-464.\n",
            "* Rachlin & Green (1972) Rachlin, H., & Green, L. (1972). Commitment, choice and self-control. _Journal of the Experimental Analysis of Behavior_, _17_, 15-22.\n",
            "* Rachlin et al. (1991) Rachlin, H., Raineri, A., & Cross, D. (1991). Subjective probability and delay. _Journal of the Experimental Analysis of Behavior_, _55_, 233-244.\n",
            "* Richards et al. (1999) Richards, J. B., Zhang, L., Mitchell, S. H., & de Wit, H. (1999). Delay or probability discounting in a model of impulsive behavior: Effect of alcohol. _Journal of the Experimental Analysis of Behavior_, _71_, 121-143.\n",
            "* Vuchinich & Simpson (1998) Vuchinich, R. E., & Simpson, C. A. (1998). Hyperbolic temporal discounting in social drinkers and problem drinkers. _Experimental and Clinical Psychopharmacology_, $6$, 292-305.\n",
            "\n",
            "## 10 Wanted: Your Old Issues!\n",
            "\n",
            "As APA continues its efforts to digitize journal issues for the PsycARTICLES database, we are finding that older issues are increasingly unavailable in our inventory. We are turning to our long-time subscribers for assistance. If you would like to donate any back issues toward this effort (preceding 1982), please get in touch with us at journals@apa.org and specify the journal titles, volumes, and issue numbers that you would like us to take off your hands.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the latex code it generated for Table 1, the table appears as:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5utYGVD5bwgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mistral OCR"
      ],
      "metadata": {
        "id": "mb4djSsJcGN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mistralai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D5ayCF7wcIW0",
        "outputId": "5ced5394-d67d-4abf-d58d-d51d8f352dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.28.1)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.11.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (6.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: invoke, eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 invoke-2.2.1 mistralai-1.9.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = os.path.join(os.getcwd(), \"data/lu_2023/Epstein et al_2003_Comparison between two measures of delay discounting in smokers.pdf\")\n",
        "print(pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNOcRh-UfKQq",
        "outputId": "938c8806-8af0-4639-e07d-ffb35a491ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/drive/MyDrive/Research/metaLLM/data/lu_2023/Epstein et al_2003_Comparison between two measures of delay discounting in smokers.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai import Mistral\n",
        "\n",
        "# load mistral api key\n",
        "with (open(\"./mistral.txt\", \"r\")) as file:\n",
        "  mistral_key = file.read()\n",
        "os.environ[\"MISTRAL_API_KEY\"] = mistral_key\n",
        "\n",
        "client = Mistral(api_key=mistral_key)\n",
        "\n",
        "uploaded_pdf = client.files.upload(\n",
        "    file={\n",
        "        \"file_name\": \"uploaded_file.pdf\",\n",
        "        \"content\": open(pdf_path, \"rb\"),\n",
        "    },\n",
        "    purpose=\"ocr\"\n",
        ")"
      ],
      "metadata": {
        "id": "mX6O4ak8fLHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get results\n",
        "\n",
        "signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
        "\n",
        "ocr_response = client.ocr.process(\n",
        "    model=\"mistral-ocr-latest\",\n",
        "    document={\n",
        "        \"type\": \"document_url\",\n",
        "        \"document_url\": signed_url.url,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "SezLNUnSfY6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the content of the response\n",
        "from mistralai.models import OCRResponse\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
        "    for img_name, base64_str in images_dict.items():\n",
        "        markdown_str = markdown_str.replace(f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\")\n",
        "    return markdown_str\n",
        "\n",
        "def get_combined_markdown(ocr_response: OCRResponse) -> str:\n",
        "  markdowns: list[str] = []\n",
        "  for page in ocr_response.pages:\n",
        "    image_data = {}\n",
        "    for img in page.images:\n",
        "      image_data[img.id] = img.image_base64\n",
        "    markdowns.append(replace_images_in_markdown(page.markdown, image_data))\n",
        "\n",
        "  return \"\\n\\n\".join(markdowns)\n",
        "\n",
        "display(Markdown(get_combined_markdown(ocr_response)))"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/None": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hvQyBaoRfg0m",
        "outputId": "86fb748c-225f-4083-83e1-5a0f742de335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Comparison Between Two Measures of Delay Discounting in Smokers \n\nLeonard H. Epstein, Jerry B. Richards,<br>Frances G. Saad, Rocco A. Paluch, and<br>James N. Roemmich<br>University at Buffalo School of Medicine and Biomedical Sciences\n\nCaryn Lerman<br>University of Pennsylvania School of Medicine\n\n\n#### Abstract\n\nAgreement between computer and questionnaire measures of delay discounting in smokers was compared. Correlations between measures for small, medium, or large rewards were significant. $\\log k$ values decreased as the reward delay increased, with values lower for the computer task than the questionnaire, with significant differences for small rewards. The 2 measures were related to smoking rate but not to age, gender, or obesity. The Bland-Altman test of agreement indicated large within-subject differences in $k$ values between the 2 measures. The size of the difference between the $\\log k$ values and magnitude of the $\\log k$ values were positively related. Results suggest $k$ values from the 2 measures are related but may not be used interchangeably.\n\n\nOne important component of self-regulation is the delay of immediate gratification to obtain later but larger rewards (Logue \\& King, 1991). When provided a choice between a small immediate reward and larger delayed rewards, people reliably discount the value of the larger delayed rewards (Bickel, Madden, \\& Petry, 1998; Richards, Zhang, Mitchell, \\& de Wit, 1999). Delay discounting has been used as an operational definition of impulsivity. The degree to which individuals discount the value of delayed consequences has been suggested to be an index of impulsivity, with greater discounting indicating greater impulsivity (Ainslie, 1975; Logue, 1988; Rachlin \\& Green, 1972; Richards et al., 1999). According to this definition of impulsivity, the behavior of individuals who discount the value of delayed consequences at a high rate is likely to be biased toward immediate consequences over more important delayed consequences. For example, cigarette smokers may choose the immediate effects of smoking over the delayed risk of emphysema and cancer. There is a growing body of evidence that individuals that engage in impulsive behaviors discount the value of delayed rewards more in laboratory tasks (Bickel \\& Marsch, 2001; Critchfield \\& Kollins, 2001). For example, several studies with drug-dependent individuals have shown that drug users discount the value of delayed rewards more than\n\n[^0]nondrug users. This has been reported for opioid-dependent individuals (Kirby, Petry, \\& Bickel, 1999; Madden, Petry, Badger, \\& Bickel, 1997), alcohol abusers (Vuchinich \\& Simpson, 1998), cigarette smokers (Bickel, Odum, \\& Madden, 1999; Mitchell, 1999), and individuals with unspecified histories of drug dependence (Allen, Moeller, Rhoades, \\& Cherek, 1998). These results indicate that there are large individual differences in delay discounting and that delay discounting may be a valid model of impulsive behavior in humans.\n\nThe most commonly used procedure to measure discounting (Rachlin, Raineri, \\& Cross, 1991) determines the value of delayed rewards by presenting the participant with two cards-the amount of the delayed reward (e.g., $\\$ 100$ in 1 year) is on one card and the amount of an immediate reward is on the second card (e.g., $\\$ 25$ right now). The participants are presented with an ascending sequence of immediate amount cards starting at a low amount and asked whether they prefer the immediate or the delayed reward. The point at which they switch from the delayed to the immediate amount is used to determine an indifference point that indicates how much they value the delayed reward. The same procedure is usually repeated for each delayed reward using a descending sequence to firmly establish the indifference point. A variant on this procedure is to use a computer to present the questions in a random order (Mitchell, 1999) to avoid possible order effects of asking the questions in a strict ascending or descending order.\n\nIn an attempt to decrease the number of questions required to determine indifference points, we developed a computer-based adjusting-amount (AA) procedure that adjusts the amount of the immediate alternative to determine indifference points (Richards et al., 1999). The computer generates the questions on the basis of the participant's answers to the preceding questions about preference of immediate versus delayed rewards, which allows the AA procedure to more rapidly determine indifference points. We have used this AA procedure to evaluate the influence of alcohol on discounting (Richards et al., 1999) and have shown that psychiatric patients with disorders related to\n\n\n[^0]:    Leonard H. Epstein, Jerry B. Richards, Frances G. Saad, Rocco A. Paluch, and James N. Roemmich, Department of Pediatrics, University at Buffalo School of Medicine and Biomedical Sciences; Caryn Lerman, Department of Psychiatry, University of Pennsylvania School of Medicine.\n\n    This work was supported by National Cancer Institute Grant CA88195, awarded to Leonard H. Epstein, and National Cancer Institute Grant CA63562 and Transdisciplinary Tobacco Use Research Center Grant R50 for the National Cancer Institute, awarded to Caryn Lerman.\n\n    Correspondence concerning this article should be addressed to Leonard H. Epstein, Department of Pediatrics, School of Medicine and Biomedical Sciences, University at Buffalo, State University of New York, Farber Hall, Room G56, 3435 Main Street, Building \\#26, Buffalo, New York 14214-3000. E-mail: lhenet@acsu.buffalo.edu\n\nimpulse control discount at different rates than patients who do not have disorders of impulse control (Crean, de Wit, \\& Richards, 2000). The average duration for determining 15 indifference points ( 5 indifference points for each of three reward values) for an individual participant using the AA procedure is 15 min , but this can vary as a function of the consistency of the participant's responding. If the participant is not consistent, then additional questions are asked until a consistent pattern emerges.\n\nKirby and colleagues (Kirby et al., 1999; Kirby \\& Marakovic, 1996) developed a questionnaire that samples 27 immediate versus delayed choices and takes about 5 min to complete. The Kirby questionnaire is much faster and easier to administer than the card- or computer-based procedures described above. The questionnaire provides a simple methodology for obtaining estimates of delay discounting, but, to our knowledge, this methodology has not been compared with more detailed methods for measuring discounting tasks such as the AA task.\n\nThe purpose of this study was to compare the relationship and agreement between the AA discounting task and the Kirby questionnaire for assessing discounting of monetary rewards. One approach to comparing the two measures was to calculate the correlation coefficient. Despite the common use of correlations as measures of agreement between measures, there are limitations to use of correlations for this purpose (Bland \\& Altman, 1986, 1995). For example, one measure may provide twice the value of the other, and if it does this reliably, the measures would show strong correlations, but the absolute values of the measures would not agree. Alternatively, the measures may differ in agreement at points along the continuum being measured.\n\nIt is also possible for measures to be correlated but have inconsistent relationships with important criterion variables. For example, we have shown that self-report and objectively measured physical activity are moderately related, but each of these measures of physical activity are significantly related to different sets of correlates (Epstein, Paluch, Coleman, Vito, \\& Anderson, 1996). In assessing the relationship between two measures, it is important to show not only the correspondence between the measures but also their association to other measures. If the measures are assessing the same construct, then the measures should be related in the same way to other variables.\n\nAnother way to test the agreement between estimates of delay discounting is to compare discounting of small, medium, and large rewards. Previous studies have shown that small rewards are discounted at a higher rate than large rewards (Green, Myerson, \\& McFadden, 1997; Kirby \\& Marakovic, 1996). Differential effects of reward amount on the rate of discounting as measured by the two procedures would provide information about the sensitivity of the two procedures. If there is no significant difference between the estimates of discounting for large, medium, and small amounts, and the two tasks are significantly related to each other and share similar relationships to other variables, there is greater confidence that they are measuring similar constructs.\n\nAgreement between the measures can also be studied using the Bland-Altman pairwise comparison approach\n(Bland \\& Altman, 1986, 1995). This approach is designed to assess the extent to which two measures agree and are interchangeable. The Bland-Altman method calculates the average difference between the two measures and the standard deviation of this difference-the smaller the standard deviations of the difference scores, the better the agreement. The Bland-Altman analysis also identifies whether there is a relationship between the magnitude of the variables and the degree of discrepancy between the measures.\n\n## Method\n\n## Participants\n\nParticipants were 32 male and 46 female smokers age 18 years and over. The average participant was $42.9 \\pm 10.6$ years of age, smoked $21.9 \\pm 8.1$ cigarettes per day, and had a mean body mass index $\\left(\\mathrm{BMI}=\\mathrm{kg} / \\mathrm{m}^{2}\\right)$ of $26.2 \\pm 5.2$. The ethnic distribution in the study was $90 \\%$ Caucasian, $9 \\%$ African American, and $1 \\%$ Hispanic. Thirty-two percent of participants completed high school or less; the remaining $68 \\%$ completed some college or technical school or beyond. Smokers were recruited through newspaper advertisements, brochures, flyers, and local media inviting them to participate in a smoking cessation program. Participants were excluded if they met any of the following criteria: smoked fewer than 10 cigarettes a day during the past year; had uncontrolled heart disease; were planning a pregnancy; were pregnant; were lactating; had a seizure disorder; had a history of head trauma or prior seizure; had a brain or central nervous system tumor; had a history of or were currently diagnosed with bulimia or anorexia nervosa; had diabetes; used alcohol excessively; had a current addiction to opiates, cocaine, or stimulants; had current depression or mania; were using chewing tobacco or snuff; or had an Axis I major psychiatric disorder. At the initial screening session, smokers were offered the opportunity to participate in a supplemental study to collect delay-discounting measures.\n\n## Design and Procedure\n\nAt the initial visit participants completed standard questionnaires assessing demographics of age, gender, smoking history, and number of cigarettes smoked per day (Lerman et al., 1997). Height and weight were taken to calculate BMI. After collection of this information, participants completed the two delay-discounting measures, presented in a random order across participants.\n\nThe monetary-choice questionnaire developed by Kirby et al. (1999) included a fixed set of 27 choices between smaller immediate rewards and larger delayed rewards. An example choice is \"Would you prefer $\\$ 55$ today or $\\$ 75$ in 61 days?\" Participants indicated which alternative they would prefer by circling one alternative for each item of the questionnaire. The range of delays included in the Kirby questionnaire was 7 to 186 days. The questionnaire is a sensitive measure of discounting-discriminating discount rates of drug users and nonusers (Kirby et al., 1999; Madden et al., 1997). The Kirby delay-discounting questionnaire was scored using the procedures described by Kirby and colleagues (Kirby et al., 1999). The $k$ values provided by the Kirby questionnaire have a range of 10 discrete steps: $.00016, .00025$, $.00063, .0016, .0039, .010, .0126, .065, .16$, and .25 . Each participant was assigned one of these $k$ values on the basis of his or her answers to the 27 items. The Kirby questionnaire provided $k$ values for high ( $\\$ 85, \\$ 80, \\$ 75$ ), medium ( $\\$ 60, \\$ 55, \\$ 50$ ), and low ( $\\$ 35$, $\\$ 30, \\$ 25$ ) value delayed rewards. Previous research using this procedure (Kirby et al., 1999) showed high value monetary rewards were discounted less than lower value monetary rewards.\n\nParticipants also completed a computerized AA choice procedure to assess discounting of delayed reinforcers (Richards et al., 1999). This procedure has been shown to discriminate between psychiatric outpatients with and without a history of impulsive behavior (Crean et al., 2000). Participants were presented with an average of 110 questions. The exact number of questions was determined by the computer test procedure and by how consistently the participants answered the questions. Participants chose between amounts of money available after different delays and amounts of money available immediately. The amount of immediate money was adjusted (by the computer) to determine the point at which the participants were indifferent about the immediate and delayed amounts.\n\nThe time delays of the monetary rewards consisted of $2,30,180$, 365 , or 730 days. Discount functions for the different amounts of delayed money ( $\\$ 85, \\$ 55, \\$ 25$ ) were determined. An example question is \"Which would you prefer, $\\$ 65$ today or $\\$ 85$ two days from now?\" Participants used the computer mouse to indicate which reward they would prefer. The AA procedure used the answers to previous questions to narrow the range of values from which the value for the next question was selected. This reduced the number of questions needed to estimate the indifference points for the delay and probability discount functions for an individual compared with standard ascending-descending procedures (Rachlin et al., 1991). The amount of immediate money the participant judged to be equivalent to the delayed reward was taken to indicate the subjective value of the delayed rewards. These points of subjective equality were called indifference points. The adjusting nature of the task was masked by not using a predictable algorithm for determining the adjusted value for the subsequent questions. The algorithm used by the AA procedure is described in detail in Richards et al., 1999.\n\nDiscounting of reward value as a function of delay (Green, Fry, \\& Myerson, 1994) is described by a hyperbolic discount function (Mazur, 1987). The formula used to determine this value is as follows: Value $=\\mathrm{A} /(1+k \\mathrm{D})$, where \"A\" represents the amount of the delayed reward, \"D\" represents the delay, and $k$ represents a free parameter. Indifference points were determined for the five different delays-2, 30, 180, 365, and 730 days-using the AA procedure. The hyperbolic discount equation was then fit to indifference points using a nonlinear curve-fitting program (Origin 6.0, Microcal Software, Inc., Northampton, MA) to determine the value of $k$. In addition to the $k$ values, the curve-fitting procedure provided goodness-of-fit measures, chi-square, and the coefficient of determination $\\left(r^{2}\\right)$. Outlying $k$ values that were greater than 1.0 or had $r^{2}$ values less than 0.4 were not included in the analysis.\n\nThe $\\log$ of the $k$ values for the three different delayed amounts were used to normalize the distribution of $k$ values for the computer task. Deviations from normality were determined by calculating skewness statistics and their standard errors. Distributions that have skewness/S.E. skewness values that are greater than 1.96 are considered not to be normally distributed. Before log transformations, the skewness/S.E. skewness values for small, medium, and large rewards were $15.7,17.7$, and 13.6 , respectively, for the computer task, and $14.1,15.8$, and 15.5 , respectively, for the Kirby questionnaire. Log transformations reduced the values for small, medium, and large rewards to $0.97,1.36$, and 1.64 , respectively, for the computer task, and $2.56,0.64$, and 0.51 , respectively, for the Kirby questionnaire. Thus, log transformations drastically reduced skewness for every measure, and with the exception of small rewards for the Kirby questionnaire, the distributions did not deviate from normality after log transformation. The means and standard deviations of the log values for the Kirby questionnaire across the three reward values were $-1.87 \\pm 0.55,-2.10 \\pm 0.59$, and $-2.18 \\pm 0.62$, whereas values for the AA procedures for the\nthree reward values were $-2.12 \\pm 0.68,-2.14 \\pm 0.75$, and -2.23 $\\pm 0.75$. The $\\log$ of the $k$ value was used for all analyses.\n\nParticipants were given a one-in-six chance of receiving the reward that they chose on one of the tasks to encourage accurate responding (Griffiths, Rush, \\& Puhala, 1996). At the end of the session, participants selected a ball from a bingo device that corresponded to choice made on one of each task. If participants rolled a 6 on a dice they received the reward they chose.\n\nOne important consideration in comparing the two tasks was the difference in delay between the two tasks. The Kirby questionnaire has delays up to 186 days, whereas the computer task has delays up to 730 days. Because the computer task also includes a 180-day delay, we compared $\\log k$ values for the computer task using all the delays and delays up to 180 days. The $\\log k$ values were very similar, with correlations between measures using all the delays and those using only delays up to 180 days of $.94, .93$, and .92 , respectively, for small, medium, and large rewards. In addition, a within-subjects analysis of variance (ANOVA) was used to compare the $\\log k$ values between the two sets of delays (all the delays vs. delays up to 180 days) as one within-variable and reward value $(\\$ 25, \\$ 55, \\$ 85)$ as the second within-variable. The analysis showed a significant difference between reward values, $F(2,148)=6.01$, $p<.01$, but there were no differences $(p>.10)$ as a function of length of delay or the interaction of Length of Delay $\\times$ Reward Value. The means and standard deviations for the full range of delays across the three reward values $(\\$ 25, \\$ 55, \\$ 85)$ were -2.12 $\\pm 0.68,-2.14 \\pm 0.75,-2.23 \\pm 0.75$, whereas the corresponding means and standard deviations for delays up to 180 days were $-2.05 \\pm 0.65,-2.09 \\pm 0.73,-2.19 \\pm 0.74$. Because the values were very similar, we used the $k$ values for the longer delay, as these were based on more data points (five delays vs. three delays) and provided a more stable estimate of $k$ values.\n\n## Analytic Plan\n\nThe Pearson product-moment correlation coefficient between the two measures was calculated, as was the correlation between the average $k$ values on each task and cigarettes per day, education, BMI, gender, and age. To ensure that the correlations were performed on variables that were scaled similarly, variables were converted to $z$ scores prior to correlations being performed. A repeated measures ANOVA, with Task as one within-factor and Amount (small, medium, large) as the second within-factor, was used to determine whether the $k$ values obtained from the two tasks were significantly different.\n\nThe Bland-Altman analysis also was completed to compare (Bland \\& Altman, 1986, 1995) agreement between the two measures. This procedure calculates the difference between the $\\log k$ values for the two measures (computer task - Kirby questionnaire) and the average of the $\\log k$ values of the two measures ((computer task + Kirby questionnaire)/2) for each participant. These data were graphed, and the correlation and slope based on the regression model between the difference of the two measures and the average $\\log k$ were calculated. The first indicator of agreement is the average of the difference scores. Ideally, this difference would be 0 . The second indicator of agreement is the variability of the discrepancy scores. The Bland-Altman analysis uses the difference between 2 standard deviations from the mean difference as an indicator of within-subject discrepancy. The larger these limits of agreement, the greater the within-subject discrepancy. The third indicator of agreement establishes the regression between the difference score and the average of the two $\\log k$ values to determine whether the degree of discrepancy reliably changes as a function of the size of $k$.\n\n## Results\n\nFigure 1 shows the best-fitting hyperbolic discount function to the median of the $k$ values for the three reward values of the AA task. As shown by the plots in Figure 1, the indifference points obtained by the AA task were well described by the hyperbolic discount function at each reward value. The mean $r^{2}$ values for all participants for the small, medium, and large rewards were $.83, .84, .85$, respectively. There is no curve fit for the Kirby questionnaire because it is based on the assumption that the hyperbolic discount equation describes each individual's choices on the questionnaire. Thus, there is no way to assess goodness of fit or how well the assumption of hyperbolic discounting describes each individual's answers to the questions on the Kirby questionnaire.\n\nThe average $k$ values for the AA task and the Kirby questionnaire were strongly correlated ( $r=.82, p<.001$ ), as were the correlations for small, medium, and large amounts ( $r \\mathrm{~s}=.74-.80, p \\mathrm{~s}<.001$ ). These values, with the best-fitting regression between the two, are shown in Figure 2. There are positive slopes of $.62, .60, .60$, and .66 for the average, small, medium, and large values, respectively,\nsuggesting that the Kirby questionnaire shows an increase of .60 to $.66 \\log k$ values for every 1.0 increase in the AA computer task $\\log k$ value.\n\nCorrelations between the AA task and Kirby questionnaire and cigarettes per day, BMI, gender, and age are shown in Table 1. The degree of relationship between each measure of discounting and the predictors were similar. For example, more cigarettes smoked per day predicted higher impulsivity scores on the AA task $(r=.23, p<.05)$ and on the Kirby questionnaire ( $r=.27, p<.025$ ). BMI, gender, and age did not correlate with either measure. Gender was marginally related to average $k$ values on the AA task ( $p=$ .053), although it was not close to being significant ( $p=$ .65) for the Kirby questionnaire.\n\nThe comparison of the $\\log k$ values between the two tasks showed there was a significant interaction between task and reward value, $F(2,154)=12.56, p<.001$, as the degree of discounting decreased for the computer task from small to medium to large rewards from -1.94 to -2.14 to -2.23 , respectively, whereas questionnaire values for small to medium to large rewards changed from -1.87 to -2.10 to -2.18 , respectively. Post hoc linear mean comparisons at each level of reward revealed that there were significant\n![img-0.jpeg](None)\n\nFigure 1. The best fitting hyperbolic discount functions to the median of the $k$ values for small, medium, or large reward values for the computer task. The top left plot shows the best fitting hyperbolic discount functions for the small, medium, and large rewards on the same graph, with the monetary reward values proportional, whereas the other graphs show the hyperbolic functions for the monetary reward values used.\n\n![img-1.jpeg](None)\n\nFigure 2. Scatterplot of $\\log k$ values for the computer task and the Kirby questionnaire. The best fitting regression line (solid line) has been fitted to the data. The dashed line is the line of identity. The top left plot shows the best fitting regression line to the $k$ values averaged across the small, medium, and large reward amounts.\ndifferences for the small reward, $F(1,77)=23.72, p<$ .001 , within both measures but not within the medium reward, $F(1,77)=0.50, p>.05$, or large reward, $F(1$, $77)=0.76, p>.05$. The change in $k$ values with increasing\n\nTable 1\nCorrelation of the Computer Task and the Kirby\nQuestionnaire to Descriptive Variables\n\n|  |  |  | Kirby |  | Computer |  |\n| :-- | :--: | :--: | :--: | :--: | :--: | :--: |\n| Variable | $M$ | $S D$ | $r$ | $p$ | $r$ | $p$ |\n| Cigarettes/day | 22.0 | 8.2 | .273 | .015 | .234 | .039 |\n| BMI | 26.3 | 5.3 | -.014 | .903 | -.057 | .618 |\n| Gender $^{a}$ |  |  | .053 | .648 | .152 | .053 |\n| Age | 42.9 | 10.7 | -.039 | .736 | -.095 | .409 |\n\nNote. All the values were converted to $z$ scores before Pearson product-moment correlations were computed, with the exception of values for gender, for which a point-biserial correlation between gender and $z \\log$ values was determined. $\\mathrm{BMI}=$ body mass index. ${ }^{a} n=32$ for men; $n=46$ for women.\nreward values was associated with a main effect of reward levels, $F(2,154)=33.93, p<.001$, across the two tasks. In addition, there was a significant main effect of task, $F(1$, $77)=6.23, p<.02$ ), as the average for the computer task $(-2.13)$ was significantly lower than the average for the Kirby questionnaire ( -1.99 ).\n\nFinally, Bland-Altman plots for average, small, medium, and large amounts are shown in Figure 3. This figure shows that the average discrepancy is $-.14,-.25,-.04$, and -.05 for the average, small, medium, and large amounts, respectively. Thus, the discrepancy between the two measures is greater for small rewards, as shown above in the ANOVA. The range of values encompassed by 2 standard deviations of the discrepancy scores is also shown in Figure 3. The 2 standard deviation limits of agreement were .683 to -.969 , .662 to $-1.166,0.935$ to -1.013 , and .869 to -.959 for the average, small, medium, and large amounts, respectively. The limits of agreement indicate that the range of variation in the discrepancy scores covered by 2 standard deviations from the mean was $40 \\%$ to $50 \\%$ of the value of the mean $k$\n\n![img-2.jpeg](None)\n\nFigure 3. Bland-Altman plots for the difference between the $\\log k$ values for the computer task and the Kirby questionnaire versus the magnitude of the $\\log k$ values for the average, small, medium, and large rewards. The 2 standard deviations of the differences are shown to provide an indication of the variability in difference scores. The short dashed line indicates the mean difference between methods, the solid lines indicate 2 standard deviation limits of agreement, the long dashed line indicates relationship between difference scores and average magnitude of the scores. See text for a detailed description.\nvalue. For example, in the case of the $k$ values for the medium reward amount, 2 standard deviations of the discrepancy scores divided by the mean of the two methods for measuring the $k$ value was 0.46 . These results show that there were substantial differences in the values of $k$ assigned to the same participant by the two methods for measuring $k$. The plots in Figure 3 indicate there are significant positive correlations for average, small, medium, and large amounts ( $r \\mathrm{~s}=.45, .30, .35$, and .31 , respectively; $p \\mathrm{~s}<.01$ ). The positive slopes $(0.31,0.24,0.270 .21)$ associated with these correlations indicate that for each amount of reward, as the values of the measures increased, the discrepancy between the two measures also increased.\n\nThe Kirby questionnaire was designed to sample choices that were representative of a range of $k$ values from .00016 to .25 . In the current study no participant had lower discounting values than .00016 , and only 2 participants had higher discounting values than 0.25 in the computer task. If the Bland-Altman analysis is done without these 2 participants, the mean discrepancy is decreased from -0.143 to\n$-0.177 k$ values, and the standard deviation is reduced from 0.413 to $0.361 k$ values. The range of scores that capture 2 standard deviations of the measures shifts from -0.969 to 0.683 for all participants to -0.899 to 0.545 for participants who scored inside of the Kirby questionnaire range. The relationship between mean discrepancy and magnitude of average $k$ decreased from 0.45 to 0.36 (both $p \\mathrm{~s}<.01$ ), and slope of the regression line decreased from 0.31 to 0.22 . Thus, even without these 2 participants there is a considerable discrepancy, and the degree of discrepancy is still positively associated with magnitude of discounting.\n\n## Discussion\n\nThe results of this study show that the AA procedure and the Kirby questionnaire are strongly related for the average discounting values and discounting at each of three reward amounts in smokers. Likewise, the AA procedure and the Kirby questionnaire correlate similarly with other variables,\n\nsuch as cigarettes smoked and education. The degree of correspondence between the two measures indicates that both procedures were measuring similar choice processes.\n\nComparison of $k$ values across both tasks showed decreases in discounting as the reward value of the delayed alternative increases and showed that the Kirby questionnaire produces greater levels of overall discounting than the AA procedure. The difference was greatest in comparing $k$ values for small rewards. One possible explanation for the difference between the methods was that participants may have discounting values that are outside the range of the 10 Kirby $k$ values ranging from .00016 to .25 . Removing the 2 participants who scored outside the range of $k$ scores that the Kirby measures did not appreciably change the variability or the pattern of discrepancy. A second possibility is that the Kirby questionnaire is less sensitive than the AA procedure (particularly at larger values of $k$ ) because it provides only 10 discrete $k$ values, whereas the AA procedure provides a continuous measure of $k$. The difference between the 10 discrete estimates of $k$ provided by the Kirby questionnaire increases logarithmically as the value of $k$ increases, so there is a larger distance between possible discrete $k$ values in the Kirby questionnaire at the larger values of $k$.\n\nThe Bland-Altman (Bland \\& Altman, 1986, 1995) plots showed the limits of agreement, as measured by 2 standard deviations for the discrepancy, between the measures was large. There was a pattern in the comparison of the discrepancy between the two measures, with the Kirby questionnaire scoring lower than the AA procedure when the $k$ values were low and the Kirby questionnaire scoring greater when the $k$ values were greater. These results suggest that the measures may not be interchangeable across all levels of $k$ values.\n\nAn investigator could draw different conclusions from the results of the standard correlational techniques, which demonstrated that the measures were strongly correlated ( $r$ s of .74 to .82 ), and that of the Bland-Altman tests of agreement. As discussed by Bland and Altman (Bland \\& Altman, 1986), the discrepancy in the outcomes of the correlational and Bland-Altman analyses is because correlational analyses test the strength of the relationship between two measures but not the agreement between two measures. A high correlation can exist between scores if the scores lie along the same line, even if the scale of one axis is twofold the other axis. There is agreement only if the scores lie along the line of identity, which has a slope of 1.0. As shown in Figure 2, the relationship between the Kirby questionnaire and the AA procedure has a slope of approximately 0.6 rather than 1.0 and, therefore, the points do not lie along the line of identity. Thus, as shown in the present data, a high correlation between two sets of measurement data does not mean that there is agreement between the two measures. Because there is no \"gold standard\" for measuring the value of $k$, it is not possible to determine which measure is the most accurate measure of discounting. The usefulness of each measure depends on the situation in which it is used.\n\nThe Kirby questionnaire provides a very efficient method for obtaining estimates of discounting, whereas the AA procedure may provide a more sensitive measure of dis-\ncounting. An advantage of the Kirby questionnaire is the opportunity to collect discounting data on large samples of participants at very little time and cost, which may be very useful in field and epidemiological studies. The questionnaire may be particularly useful when the emphasis is not on individual change but rather on characterizing trends in particular samples. There are many situations in which a detailed measure of discounting is needed, and a measure in which standard diagnostics for evaluating the fit of the hyperbolic discount function are needed. In these cases the preferred method is the computer-based AA procedure.\n\nThere are several design considerations that might influence the interpretation of the results. The questionnaire and computer task provide alternative formats to determine delay discounting, with the questionnaire involving a paper-and-pencil response format and the computer task involving responding on a computer keyboard. Although the questions that are asked of the participant are very similar, it is possible that some of the differences in $k$ values between the tasks are due to differences in response formats. This study attempted to reduce any potential limitations of using hypothetical rewards by having participants receive immediate or delayed rewards on a probabilistic basis, such that participants had a one-in-six chance of receiving one of their choices. Recent research (Johnson \\& Bickel, 2002) has shown that similar discounting functions are obtained when using hypothetical or real rewards, making it easier to implement future studies comparing different methods of measuring delay discounting by using only hypothetical rewards. Finally, all the participants in this study were smokers, who have been shown to be more impulsive on delay discounting measures than nonsmokers (Bickel et al., 1999; Mitchell, 1999). It is possible that a different relationship between measures would be obtained if a different population was studied.\n\nThere are alternatives to the Kirby and AA procedures for measuring discounting in the laboratory. The most common method for measuring discounting is to ask a prescribed set of questions about every possible combination of delay and reward. These procedures usually systematically increase or decrease the immediate amount (Rachlin et al., 1991), although procedures that randomize the questions have also been used (Mitchell, 1999). There is no gold standard for measurement of delay discounting, and as research in delay discounting and impulsivity matures, identification of sensitive and psychometrically sound measures are needed to provide comparability of major findings across studies. Future researchers may want to study the agreement between alternative laboratory methods to assess discounting to provide information needed to establish a standard measure of discounting.\n\n## References\n\nAinslie, G. (1975). Specious reward: A behavioral theory of impulsiveness and impulse control. Psychological Bulletin, 82, 463-496.\nAllen, T. J., Moeller, F. G., Rhoades, H. M., \\& Cherek, D. R. (1998). Impulsivity and history of drug dependence. Drug and Alcohol Dependence, 50, 137-145.\n\nBickel, W. K., Madden, G. J., \\& Petry, N. M. (1998). The price of change: The behavioral economics of drug dependence. Behavior Therapy, 29, 545-565.\nBickel, W. K., \\& Marsch, L. A. (2001). Toward a behavioral economic understanding of drug dependence: Delay discounting processes. Addiction, 96, 73-86.\nBickel, W. K., Odum, A. L., \\& Madden, G. J. (1999). Impulsivity and cigarette smoking: Delay discounting in current, never, and ex-smokers. Psychopharmacology, 146, 447-454.\nBland, J. M., \\& Altman, D. G. (1986). Statistical methods for assessing agreement between two methods of clinical measurement. Lancet, 1, 307-310.\nBland, J. M., \\& Altman, D. G. (1995). Comparing methods of measurement: Why plotting difference against standard method is misleading. Lancet, 346, 1085-1087.\nCrean, J. P., de Wit, H., \\& Richards, J. B. (2000). Reward discounting as a measure of impulsive behavior in a psychiatric outpatient population. Experimental and Clinical Psychopharmacology, 8, 155-162.\nCritchfield, T. S., \\& Kollins, S. H. (2001). Temporal discounting: Basic research and the analysis of socially important behavior. Journal of Applied Behavior Analysis, 34, 101-122.\nEpstein, L. H., Paluch, R. A., Coleman, K. J., Vito, D., \\& Anderson, K. (1996). Determinants of physical activity in obese children assessed by accelerometer and self-report. Medicine \\& Science in Sports \\& Exercise, 28, 1157-1164.\nGreen, L., Fry, A. F., \\& Myerson, J. (1994). Discounting of delayed rewards: A life-span comparison. Psychological Science, 5, 33-36.\nGreen, L., Myerson, J., \\& McFadden, E. (1997). Rate of temporal discounting decreases with amount of reward. Memory and Cognition, 25, 715-723.\nGriffiths, R. R., Rush, C. R., \\& Puhala, K. A. (1996). Validation of the multiple-choice procedure for investigating drug reinforcement in humans. Experimental and Clinical Psychopharmacology, 4, 97-106.\nJohnson, M. W., \\& Bickel, W. K. (2002). Within-subject comparison of real and hypothetical money rewards in delay discounting. Journal of the Experimental Analysis of Behavior, 77, $129-146$.\nKirby, K. N., \\& Marakovic, N. N. (1996). Delay-discounting probabilistic rewards: Rates decrease as amounts increase. Psychonomic Bulletin \\& Review, 3, 100-104.\n\nKirby, K. N., Petry, N. M., \\& Bickel, W. K. (1999). Heroin addicts have higher discount rates for delayed rewards than non-drugusing controls. Journal of Experimental Psychology: General, $128,78-87$.\nLerman, C., Gold, K., Audrain, J., Lin, T. H., Boyd, N. R., Orleans, C. T., et al. (1997). Incorporating biomarkers of exposure and genetic susceptibility into smoking cessation treatment: Effects on smoking-related cognitions, emotions, and behavior change. Health Psychology, 16, 87-99.\nLogue, A. W. (1988). Research on self-control: An integrating framework. Behavioral and Brain Sciences, 11, 665-709.\nLogue, A. W., \\& King, G. R. (1991). Self-control and impulsiveness in adult humans when food is a reinforcer. Appetite, 17, $105-120$.\nMadden, G. J., Petry, N. M., Badger, G. J., \\& Bickel, W. K. (1997). Impulsive and self-control choices in opioid-dependent patients and non-drug-using control participants: Drug and monetary rewards. Experimental and Clinical Psychopharmacology, 5, 256-262.\nMazur, J. E. (1987). An adjusting procedure for studying delayed reinforcement. In M. L. Commons, J. E. Mazur, J. A. Nevin, \\& H. Rachlin (Eds.), Quantitative analyses of behavior: The effect of delay and of intervening events on reinforcement value (Vol. 5, pp. 55-73). Hillsdale, NJ: Erlbaum.\nMitchell, S. H. (1999). Measures of impulsivity in cigarette smokers and non-smokers. Psychopharmacology, 146, 455-464.\nRachlin, H., \\& Green, L. (1972). Commitment, choice and selfcontrol. Journal of the Experimental Analysis of Behavior, 17, $15-22$.\nRachlin, H., Raineri, A., \\& Cross, D. (1991). Subjective probability and delay. Journal of the Experimental Analysis of Behavior, 55, 233-244.\nRichards, J. B., Zhang, L., Mitchell, S. H., \\& de Wit, H. (1999). Delay or probability discounting in a model of impulsive behavior: Effect of alcohol. Journal of the Experimental Analysis of Behavior, 71, 121-143.\nVuchinich, R. E., \\& Simpson, C. A. (1998). Hyperbolic temporal discounting in social drinkers and problem drinkers. Experimental and Clinical Psychopharmacology, 6, 292-305.\n\nReceived May 10, 2002\nRevision received October 22, 2002\nAccepted October 28, 2002\n\n# Wanted: Your Old Issues! \n\nAs APA continues its efforts to digitize journal issues for the PsycARTICLES database, we are finding that older issues are increasingly unavailable in our inventory. We are turning to our long-time subscribers for assistance. If you would like to donate any back issues toward this effort (preceding 1982), please get in touch with us at journals@apa.org and specify the journal titles, volumes, and issue numbers that you would like us to take off your hands."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2: Dynamic Effec Size Calculation with ReAct Agent"
      ],
      "metadata": {
        "id": "fDQiWAR8fo9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load api key\n",
        "import openai\n",
        "import os\n",
        "with open(\"./api_key.txt\", \"r\") as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =api_key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# specify file path\n",
        "file_folder = \"/drive/MyDrive/Research/metaLLM\"\n",
        "os.chdir(file_folder)\n",
        "\n",
        "# For Google Colab and Activeloop while waiting for Activeloop (April 2024) pending new version\n",
        "#This line writes the string \"nameserver 8.8.8.8\" to the file. This is specifying that the DNS server the system\n",
        "#should use is at the IP address 8.8.8.8, which is one of Google's Public DNS servers.\n",
        "with open('/etc/resolv.conf', 'w') as file:\n",
        "   file.write(\"nameserver 8.8.8.8\")\n",
        "\n",
        "# load api key\n",
        "import openai\n",
        "import os\n",
        "with open(\"./api_key.txt\", \"r\") as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =api_key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "#Retrieving and setting the Activeloop API token\n",
        "f = open(\"./activeloop.txt\", \"r\")\n",
        "API_token=f.readline().strip()\n",
        "f.close()\n",
        "ACTIVELOOP_TOKEN=API_token\n",
        "os.environ['ACTIVELOOP_TOKEN'] =ACTIVELOOP_TOKEN"
      ],
      "metadata": {
        "id": "TKZ8AEHgh4Rs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load OCR extracted papers\n",
        "import pickle\n",
        "\n",
        "with open('./data/ocr/paper_ocr_list_nougat.pkl', 'rb') as f:\n",
        "    paper_ocr_list = pickle.load(f)"
      ],
      "metadata": {
        "id": "vmoxy0ZviOyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "full_prompt = \"\"\"Here is the full content of a research paper:\n",
        "\n",
        "{full_documents}\n",
        "\n",
        "Based on the above paper, please:\n",
        "\n",
        "Act as a experienced psychology researcher, extract statistics and the corresponding sample size indicating the age effect on delay discounting in this paper.\n",
        "Delay discounting is typically measured by k value, area under the curve (AUC), or indifference points.\n",
        "The statistics should be relevant and sufficient for calculating an effect size like Cohen's d or Pearson's r.\n",
        "\n",
        "Structure the output as follows:\n",
        "\n",
        "1. For each reported statistics, provide the following structured data:\n",
        "    - Effect Context: Briefly describe the effect being measured so that its direction can be obtained. (e.g., \"Older adults showed higher temporal discounting\").\n",
        "    - Reported Statistics: Extract all available statistics needed to calculate effect sizes:\n",
        "        - For mean/sd: Report sample size, mean, and standard deviation for each group (e.g., \"Group 1 (adolescents): n=30, Mean=5.2, SD=1.3; Group 2 (adults): n=35, Mean=6.8, SD=1.5\").\n",
        "        - For t-tests: Extract t-value, degrees of freedom, and sample sizes for each group (e.g., \"t=2.5, df=63, n1=30, n2=35\").\n",
        "        - For ANOVA or F-statistics: Report F-value, degrees of freedom, and sample sizes.\n",
        "        - For eta-squared or partial eta-squared: Extract eta-squared value and specify if it's partial (e.g., partial eta-squared = 0.05, n=90).\n",
        "        - If the paper directly reported effect size in the metric of Cohen's d or Pearson's r, directly report them (e.g., r = 0.150, n=90).\n",
        "\n",
        "2. Output format (example for a mean/sd comparison):\n",
        "    [Effect Context]: Older adults showed less discounting.\n",
        "    [Reported Statistics]: Group 1: n=30, Mean=5.2, SD=1.3; Group 2: n=35, Mean=6.8, SD=1.5\n",
        "\n",
        "Additional guidelines:\n",
        "1. If multiple statistics are reported in different studies, conditions, samples (e.g., smokers), methods (e.g., indifference points) of the paper, provide each one separately in this format.\n",
        "2. For the effect context, be specific about the direction of the effect (e.g., Adolescents showed higher temporal discounting).\n",
        "3. Please remember to go through all tables to check whether there are statistics related to discounting for each age group OR correlations between age and discounting.\n",
        "4. DO NOT extract irrelevant statistics like correlation between age and IQ or SES.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "3Hr2whnGfvwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extractor"
      ],
      "metadata": {
        "id": "4cKV8DLCjWuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define extractor\n",
        "import re\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "class Extractor:\n",
        "  def __init__(self, model, prompt):\n",
        "    self.model = model\n",
        "    self.prompt = prompt\n",
        "\n",
        "  def clean_references(self, content):\n",
        "    \"\"\"\n",
        "    Remove references from the extracted text. This function removes citations\n",
        "    like [1], [2], and the entire References section if present.\n",
        "    \"\"\"\n",
        "    # Remove the References section if it exists\n",
        "    content = re.sub(r'(References|Discussion)\\s.*', '', content, flags=re.DOTALL)\n",
        "\n",
        "    return content\n",
        "\n",
        "  def extract_statistics(self, document):\n",
        "    # load the ocr text\n",
        "    ocr_documents = \"/n\".join([doc.text for doc in document])\n",
        "    #print(\"successfully loaded the paper\")\n",
        "    ocr_documents = self.clean_references(ocr_documents)\n",
        "    #print(\"successfully cleaned the paper\")\n",
        "    # set up the prompt\n",
        "    full_prompt = self.prompt.format(full_documents = ocr_documents)\n",
        "\n",
        "    # extract effect sizes\n",
        "    response = client.chat.completions.create(\n",
        "        model = self.model,\n",
        "        temperature = 0.0,\n",
        "        messages=[\n",
        "                {\"role\": \"system\", \"content\": \"\"},\n",
        "                {\"role\": \"user\", \"content\": full_prompt},\n",
        "            ])\n",
        "\n",
        "    # Split the text into chunks if multiple effects were detected\n",
        "    response = response.choices[0].message.content\n",
        "    es_list = re.split(r'\\n+\\s*(?=\\d+\\. )', response.strip())\n",
        "\n",
        "    return es_list"
      ],
      "metadata": {
        "id": "WHVqn4Q1hqO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract statistics based on full text\n",
        "extractor = Extractor(model = \"gpt-4o\", prompt = full_prompt)\n",
        "es_list = extractor.extract_statistics(paper_ocr_list[1])"
      ],
      "metadata": {
        "id": "-43KQbdGhtqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAzhYgBupz80",
        "outputId": "368ce957-91a6-42cf-909b-3727b41a71a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"1. **Effect Context**: Young adults showed a decrease in delay discounting with age.\\n   - **Reported Statistics**: Kendall's tau = -0.23, p = 0.005, n = 84\",\n",
              " \"2. **Effect Context**: Older adults showed an increase in delay discounting with age.\\n   - **Reported Statistics**: Kendall's tau = 0.15, p = 0.051, n = 104\",\n",
              " \"3. **Effect Context**: Physical age showed a stronger association with delay discounting for young adults.\\n   - **Reported Statistics**: Kendall's tau = -0.27, p = 0.001, n = 84\",\n",
              " \"4. **Effect Context**: Physical age showed a stronger association with delay discounting for older adults.\\n   - **Reported Statistics**: Kendall's tau = 0.17, p = 0.028, n = 104\",\n",
              " \"5. **Effect Context**: No significant association between chronological age and delay discounting in the middle-aged group.\\n   - **Reported Statistics**: Kendall's tau = -0.03, p = 0.78, n = 54\",\n",
              " \"6. **Effect Context**: Life history strategy negatively associated with delay discounting across all ages.\\n   - **Reported Statistics**: Kendall's tau = -0.15, p = 0.002, n = 242\\n\\nThese statistics provide insights into the age-related effects on delay discounting, allowing for the calculation of effect sizes such as Cohen's d or Pearson's r where applicable.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(es_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSMiOR28p-8J",
        "outputId": "dac623d0-2016-481d-cf3b-95c46d2fb1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Censor"
      ],
      "metadata": {
        "id": "w9-eBeF_jZQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define Censor\n",
        "\n",
        "class Censor:\n",
        "    \"\"\"\n",
        "    Core 'censor' stage:\n",
        "    - Filter & normalize extractor outputs (es_list)\n",
        "    - Enforce coding protocol\n",
        "    - Return only kept, canonicalized effect texts for the coder\n",
        "\n",
        "    Since LLMs struggle with copying digits, this step only return BOOLEAN values.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, refine_prompt):\n",
        "      self.model = model\n",
        "      self.prompt = refine_prompt\n",
        "      self.prompts = []\n",
        "      self.responses = []  # Store raw responses here\n",
        "\n",
        "    def normalize_token(self, token):\n",
        "        t = (token or \"\").strip().upper()\n",
        "        if t in {\"KEEP\", \"[KEEP]\", \"K\", \"YES\", \"Y\"}:\n",
        "            return \"KEEP\"\n",
        "        if t in {\"DROP\", \"[DROP]\", \"D\", \"NO\", \"N\"}:\n",
        "            return \"DROP\"\n",
        "        return \"\"\n",
        "\n",
        "    # LLM censoring based on the protocol\n",
        "    def censor_es(self, es_list, coding_protocol):\n",
        "      # apply light filtering\n",
        "      es_list_cleaned = es_list\n",
        "      # attach protocols\n",
        "      full_prompt = self.prompt.format(coding_protocol=coding_protocol, es_list_cleaned=es_list_cleaned)\n",
        "      self.prompts.append(full_prompt)\n",
        "\n",
        "      response = client.chat.completions.create(\n",
        "        model = self.model,\n",
        "        temperature = 0.0,\n",
        "        messages=[\n",
        "                {\"role\": \"system\", \"content\": \"\"},\n",
        "                {\"role\": \"user\", \"content\": full_prompt},\n",
        "            ])\n",
        "\n",
        "      return (response.choices[0].message.content or \"\").strip()\n",
        "\n",
        "    def parse_answer_to_bool(self, answer):\n",
        "      \"\"\"\n",
        "      Parse LLM answer like 'KEEP' or 'DROP' (allow short notes like 'KEEP: reason').\n",
        "      Return True/False, or None if unparsable.\n",
        "      \"\"\"\n",
        "      first_line = (answer.splitlines()[0] if answer else \"\").strip()\n",
        "      m = re.match(r\"^\\s*([A-Za-z\\[\\]]+)\", first_line)\n",
        "      if not m:\n",
        "        return None\n",
        "      token = self.normalize_token(m.group(1))\n",
        "      if token == \"KEEP\":\n",
        "        return True\n",
        "      if token == \"DROP\":\n",
        "        return False\n",
        "      return None\n",
        "\n",
        "    def judge_one(self, item_text, coding_protocol):\n",
        "      \"\"\"\n",
        "      Judge a single item. If unparsable, fall back to False (DROP).\n",
        "      \"\"\"\n",
        "      raw = self.censor_es(item_text, coding_protocol)\n",
        "      self.responses.append(raw)\n",
        "      flag = self.parse_answer_to_bool(raw)\n",
        "      return bool(flag)\n",
        "\n",
        "    def judge_all(self, es_list, coding_protocol):\n",
        "      \"\"\"\n",
        "      Sequentially judge each item in es_list, one API call per item.\n",
        "      \"\"\"\n",
        "      results = []\n",
        "      for s in es_list:\n",
        "          results.append(self.judge_one(s, coding_protocol))\n",
        "      return results"
      ],
      "metadata": {
        "id": "4bqyiNa_mlh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coding_protocol = \"\"\"\n",
        "Inclusion Criteria:\n",
        "The text must：\n",
        "(a) related to delay discounting\n",
        "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
        "(c) focus on chronological age only\n",
        "\"\"\"\n",
        "\n",
        "single_prompt_template = \"\"\"\n",
        "You are the CENSOR in a meta-analysis pipeline.\n",
        "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
        "\n",
        "=== Coding Protocol ===\n",
        "{coding_protocol}\n",
        "=== END PROTOCOL ===\n",
        "\n",
        "=== Candidate text ===\n",
        "{es_list_cleaned}\n",
        "=== END CANDIDATE ===\n",
        "\n",
        "Rules:\n",
        "- Output ONLY one of:\n",
        "  - KEEP\n",
        "  - DROP\n",
        "  (The first word must be KEEP or DROP, followed by the reason)\n",
        "- Keep only if ALL required inclusion criteria are satisfied.\n",
        "- Do not infer from outside the candidate text.\n",
        "\n",
        "Now output KEEP or DROP (one line).\n",
        "\"\"\"\n",
        "\n",
        "censor = Censor(model=\"gpt-4o\", refine_prompt=single_prompt_template)\n",
        "flags = censor.judge_all(es_list, coding_protocol)"
      ],
      "metadata": {
        "id": "Ou0jGu5yzn-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vszvzs9U4tkw",
        "outputId": "2e4804d9-fc93-42e7-975b-544e1997c4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, False, False, True, False]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access all raw responses\n",
        "for i, response in enumerate(censor.responses):\n",
        "  print(f\"Item {i}: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBN-Sgi652Vv",
        "outputId": "36fea2a4-45ee-4924-9025-2f0ad9637638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item 0: KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age.\n",
            "Item 1: KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age only.\n",
            "Item 2: DROP because the text does not examine age effects on delay discounting across different age groups or correlations with chronological age.\n",
            "Item 3: DROP, because the text does not explicitly mention examining age effects on delay discounting, only that there is an association with physical age.\n",
            "Item 4: KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age.\n",
            "Item 5: DROP, the text does not examine age effects on delay discounting specifically, as it only mentions a general association with life history strategy across all ages without focusing on chronological age.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (prompt, response) in enumerate(zip(censor.prompts, censor.responses)):\n",
        "    print(f\"\\n=== Item {i} ===\")\n",
        "    print(f\"Prompt:\\n{prompt}\")\n",
        "    print(f\"\\nResponse:\\n{response}\")\n",
        "    print(f\"Flag: {flags[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M-0wHPAxDel",
        "outputId": "002b3aac-ff55-4b6e-9e78-2489fbb03b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Item 0 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "1. **Effect Context**: Young adults showed a decrease in delay discounting with age.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.23, p = 0.005, n = 84\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age.\n",
            "Flag: True\n",
            "\n",
            "=== Item 1 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "2. **Effect Context**: Older adults showed an increase in delay discounting with age.\n",
            "   - **Reported Statistics**: Kendall's tau = 0.15, p = 0.051, n = 104\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age only.\n",
            "Flag: True\n",
            "\n",
            "=== Item 2 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "3. **Effect Context**: Physical age showed a stronger association with delay discounting for young adults.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.27, p = 0.001, n = 84\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "DROP because the text does not examine age effects on delay discounting across different age groups or correlations with chronological age.\n",
            "Flag: False\n",
            "\n",
            "=== Item 3 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "4. **Effect Context**: Physical age showed a stronger association with delay discounting for older adults.\n",
            "   - **Reported Statistics**: Kendall's tau = 0.17, p = 0.028, n = 104\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "DROP, because the text does not explicitly mention examining age effects on delay discounting, only that there is an association with physical age.\n",
            "Flag: False\n",
            "\n",
            "=== Item 4 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "5. **Effect Context**: No significant association between chronological age and delay discounting in the middle-aged group.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.03, p = 0.78, n = 54\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "KEEP because the text is related to delay discounting, examines age effects on delay discounting, and focuses on chronological age.\n",
            "Flag: True\n",
            "\n",
            "=== Item 5 ===\n",
            "Prompt:\n",
            "\n",
            "You are the CENSOR in a meta-analysis pipeline.\n",
            "Decide whether the SINGLE statistics text should be included for the analysis according to the protocol.\n",
            "\n",
            "=== Coding Protocol ===\n",
            "\n",
            "Inclusion Criteria:\n",
            "The text must： \n",
            "(a) related to delay discounting  \n",
            "(b) examine age effects on delay discounting (e.g., a correlation, comparisons across age groups, etc)\n",
            "(c) focus on chronological age only \n",
            "\n",
            "=== END PROTOCOL ===\n",
            "\n",
            "=== Candidate text ===\n",
            "6. **Effect Context**: Life history strategy negatively associated with delay discounting across all ages.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.15, p = 0.002, n = 242\n",
            "\n",
            "These statistics provide insights into the age-related effects on delay discounting, allowing for the calculation of effect sizes such as Cohen's d or Pearson's r where applicable.\n",
            "=== END CANDIDATE ===\n",
            "\n",
            "Rules:\n",
            "- Output ONLY one of:\n",
            "  - KEEP\n",
            "  - DROP\n",
            "  (The first word must be KEEP or DROP, followed by the reason)\n",
            "- Keep only if ALL required inclusion criteria are satisfied.\n",
            "- Do not infer from outside the candidate text.\n",
            "\n",
            "Now output KEEP or DROP (one line).\n",
            "\n",
            "\n",
            "Response:\n",
            "DROP, the text does not examine age effects on delay discounting specifically, as it only mentions a general association with life history strategy across all ages without focusing on chronological age.\n",
            "Flag: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coder"
      ],
      "metadata": {
        "id": "RV_HXP3ijauK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-deeplake==0.1.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "GMK8_fgKk10l",
        "outputId": "d96a43b9-d80b-4545-d29f-16626d6dd309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-deeplake==0.1.6\n",
            "  Downloading llama_index_vector_stores_deeplake-0.1.6-py3-none-any.whl.metadata (709 bytes)\n",
            "Collecting deeplake>=3.9.12 (from llama-index-vector-stores-deeplake==0.1.6)\n",
            "  Downloading deeplake-4.4.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-deeplake==0.1.6)\n",
            "  Downloading llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake==0.1.6) (2.0.2)\n",
            "Collecting deepframe (from deeplake>=3.9.12->llama-index-vector-stores-deeplake==0.1.6)\n",
            "  Downloading deepframe-0.1.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.5)\n",
            "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.9.1)\n",
            "Collecting numpy (from deeplake>=3.9.12->llama-index-vector-stores-deeplake==0.1.6)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (11.3.0)\n",
            "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.11.10)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.22.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (2025.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake==0.1.6) (1.3.1)\n",
            "Downloading llama_index_vector_stores_deeplake-0.1.6-py3-none-any.whl (5.1 kB)\n",
            "Downloading deeplake-4.4.0-cp312-cp312-manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepframe-0.1.1-cp312-cp312-manylinux2014_x86_64.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, deepframe, llama-index-core, deeplake, llama-index-vector-stores-deeplake\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.14.7\n",
            "    Uninstalling llama-index-core-0.14.7:\n",
            "      Successfully uninstalled llama-index-core-0.14.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index 0.14.7 requires llama-index-core<0.15.0,>=0.14.7, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-cloud-services 0.6.54 requires llama-index-core>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-indices-managed-llama-cloud 0.9.4 requires llama-index-core<0.15,>=0.13.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-readers-file 0.5.4 requires llama-index-core<0.15,>=0.13.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-llms-openai 0.6.6 requires llama-index-core<0.15,>=0.14.5, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-embeddings-openai 0.5.1 requires llama-index-core<0.15,>=0.13.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-readers-llama-parse 0.5.1 requires llama-index-core<0.15,>=0.13.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "llama-index-cli 0.5.3 requires llama-index-core<0.15,>=0.13.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepframe-0.1.1 deeplake-4.4.0 llama-index-core-0.10.68.post1 llama-index-vector-stores-deeplake-0.1.6 numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index",
                  "numpy"
                ]
              },
              "id": "d69d38495f274497bb2eeac15435ebcd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplake==3.9.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "v1Gse9kjmA5x",
        "outputId": "02f27c3e-fa74-4043-88cd-62fa56a3f5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeplake==3.9.18\n",
            "  Using cached deeplake-3.9.18.tar.gz (608 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (1.26.4)\n",
            "Collecting pillow~=10.2.0 (from deeplake==3.9.18)\n",
            "  Using cached pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting boto3 (from deeplake==3.9.18)\n",
            "  Using cached boto3-1.40.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (8.3.0)\n",
            "Collecting pathos (from deeplake==3.9.18)\n",
            "  Using cached pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting humbug>=0.3.1 (from deeplake==3.9.18)\n",
            "  Using cached humbug-0.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (4.67.1)\n",
            "Collecting lz4 (from deeplake==3.9.18)\n",
            "  Using cached lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (2.10.1)\n",
            "Collecting aioboto3>=10.4.0 (from deeplake==3.9.18)\n",
            "  Using cached aioboto3-15.5.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (1.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from deeplake==3.9.18) (2.11.10)\n",
            "Collecting aiobotocore==2.25.1 (from aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18)\n",
            "  Downloading aiobotocore-2.25.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.12/dist-packages (from aioboto3>=10.4.0->deeplake==3.9.18) (24.1.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.2 in /usr/local/lib/python3.12/dist-packages (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (3.13.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.40.62,>=1.40.46 (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18)\n",
            "  Downloading botocore-1.40.61-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (2.9.0.post0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (6.7.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.12/dist-packages (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (1.17.3)\n",
            "Collecting boto3 (from deeplake==3.9.18)\n",
            "  Downloading boto3-1.40.61-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->deeplake==3.9.18)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from humbug>=0.3.1->deeplake==3.9.18) (2.32.4)\n",
            "Collecting ppft>=1.7.7 (from pathos->deeplake==3.9.18)\n",
            "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos->deeplake==3.9.18)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos->deeplake==3.9.18)\n",
            "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos->deeplake==3.9.18)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->deeplake==3.9.18) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->deeplake==3.9.18) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->deeplake==3.9.18) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->deeplake==3.9.18) (0.4.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.40.62,>=1.40.46->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.18) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.18) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->humbug>=0.3.1->deeplake==3.9.18) (2025.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (1.8.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3>=10.4.0->deeplake==3.9.18) (1.17.0)\n",
            "Downloading aioboto3-15.5.0-py3-none-any.whl (35 kB)\n",
            "Downloading aiobotocore-2.25.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.61-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humbug-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.61-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: deeplake\n",
            "  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeplake: filename=deeplake-3.9.18-py3-none-any.whl size=731754 sha256=d1af0911785963b5170a987a997fc4fad4a03e4c6f0e77244fe913a53d1bd597\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/57/2a/28e6a1a2d9e08b09e14b326b7e042428df3c0768b20b2d3318\n",
            "Successfully built deeplake\n",
            "Installing collected packages: ppft, pox, pillow, lz4, jmespath, dill, aioitertools, multiprocess, humbug, botocore, s3transfer, pathos, aiobotocore, boto3, aioboto3, deeplake\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: deeplake\n",
            "    Found existing installation: deeplake 4.4.0\n",
            "    Uninstalling deeplake-4.4.0:\n",
            "      Successfully uninstalled deeplake-4.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aioboto3-15.5.0 aiobotocore-2.25.1 aioitertools-0.12.0 boto3-1.40.61 botocore-1.40.61 deeplake-3.9.18 dill-0.4.0 humbug-0.3.2 jmespath-1.0.1 lz4-4.4.4 multiprocess-0.70.18 pathos-0.3.4 pillow-10.2.0 pox-0.3.6 ppft-1.7.7 s3transfer-0.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "9c1a83e9807f43aba78f84cb11e51fc7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index==0.10.64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "xYOrlZc7mCdW",
        "outputId": "1037bd3f-d692-48bf-e413-3f862818b666"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index==0.10.64\n",
            "  Downloading llama_index-0.10.64-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.64 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index==0.10.64) (0.9.4)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from llama-index==0.10.64) (0.5.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.64) (1.109.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.5)\n",
            "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.9.1)\n",
            "Collecting numpy<2.0.0 (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (11.3.0)\n",
            "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.11.10)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.17.3)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64) (0.1.35)\n",
            "INFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.10-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.32 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.32-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.9-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.30 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.30-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.8-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.6-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.25 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.25-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.23 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.23-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud==0.1.21 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.21-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.64) (4.13.5)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.64)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.64) (0.0.26)\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index==0.10.64)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64) (0.6.54)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.22.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.64) (2.8)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64) (2025.10.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.16.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2024.11.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.64) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.64) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.64) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (2025.2)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.43-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.42-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.41-py3-none-any.whl.metadata (2.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Using cached llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.37-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Using cached llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.53-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.53 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.53-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.52-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.52 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.52-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.51-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.51 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.51-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.34-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.50-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.49 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.50-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.49-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.49-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.48-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.48 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.48-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.47-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.47 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.47-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.33-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.46-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.45 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.46-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.45-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.45-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.44-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.44 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.44-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.43-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.43 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.43-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.42-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.42 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.42-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.41-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.41 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.40-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.40 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.39 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.29-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.28-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.27-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.33-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.33-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.32-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.31-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.31 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.31-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.30-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.30 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.30-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.28-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.28 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.29-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.28-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.27-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.27 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.27-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.26-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.26 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.26-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.25-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.24 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.25-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.24-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.24-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.23 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.22 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.64)\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.20 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.20-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.18-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.17 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.19-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.18-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.16 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.16-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.12 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.14-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.9 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.11-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.10-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.3 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.2 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting llama-cloud-services (from llama-parse>=0.4.0->llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.64)\n",
            "  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.64->llama-index==0.10.64) (1.17.0)\n",
            "Downloading llama_index-0.10.64-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, numpy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 6.1.3\n",
            "    Uninstalling pypdf-6.1.3:\n",
            "      Successfully uninstalled pypdf-6.1.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.14.7\n",
            "    Uninstalling llama-index-core-0.14.7:\n",
            "      Successfully uninstalled llama-index-core-0.14.7\n",
            "  Attempting uninstall: llama-parse\n",
            "    Found existing installation: llama-parse 0.6.54\n",
            "    Uninstalling llama-parse-0.6.54:\n",
            "      Successfully uninstalled llama-parse-0.6.54\n",
            "  Attempting uninstall: llama-index-readers-file\n",
            "    Found existing installation: llama-index-readers-file 0.5.4\n",
            "    Uninstalling llama-index-readers-file-0.5.4:\n",
            "      Successfully uninstalled llama-index-readers-file-0.5.4\n",
            "  Attempting uninstall: llama-index-llms-openai\n",
            "    Found existing installation: llama-index-llms-openai 0.6.6\n",
            "    Uninstalling llama-index-llms-openai-0.6.6:\n",
            "      Successfully uninstalled llama-index-llms-openai-0.6.6\n",
            "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
            "    Found existing installation: llama-index-indices-managed-llama-cloud 0.9.4\n",
            "    Uninstalling llama-index-indices-managed-llama-cloud-0.9.4:\n",
            "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.9.4\n",
            "  Attempting uninstall: llama-index-embeddings-openai\n",
            "    Found existing installation: llama-index-embeddings-openai 0.5.1\n",
            "    Uninstalling llama-index-embeddings-openai-0.5.1:\n",
            "      Successfully uninstalled llama-index-embeddings-openai-0.5.1\n",
            "  Attempting uninstall: llama-index-readers-llama-parse\n",
            "    Found existing installation: llama-index-readers-llama-parse 0.5.1\n",
            "    Uninstalling llama-index-readers-llama-parse-0.5.1:\n",
            "      Successfully uninstalled llama-index-readers-llama-parse-0.5.1\n",
            "  Attempting uninstall: llama-index-cli\n",
            "    Found existing installation: llama-index-cli 0.5.3\n",
            "    Uninstalling llama-index-cli-0.5.3:\n",
            "      Successfully uninstalled llama-index-cli-0.5.3\n",
            "  Attempting uninstall: llama-index\n",
            "    Found existing installation: llama-index 0.14.7\n",
            "    Uninstalling llama-index-0.14.7:\n",
            "      Successfully uninstalled llama-index-0.14.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-cloud-services 0.6.54 requires llama-index-core>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llama-index-0.10.64 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 numpy-1.26.4 pypdf-4.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index",
                  "llama_parse",
                  "numpy"
                ]
              },
              "id": "2ac950e7f152455888b5217bfe4be2ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define ES functions\n",
        "import math\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
        "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, FilterOperator\n",
        "\n",
        "def mean_to_cohens_d(y1: float, y2: float, s1: float, s2: float, n1: int, n2: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Cohen's d and its variance using mean/sd for two independent groups.\n",
        "\n",
        "    Arguments:\n",
        "    y1 : float : Mean of the first group\n",
        "    y2 : float : Mean of the second group\n",
        "    s1 : float : Standard deviation of the first group\n",
        "    s2 : float : Standard deviation of the second group\n",
        "    n1 : int   : Sample size of the first group\n",
        "    n2 : int   : Sample size of the second group\n",
        "\n",
        "    Returns:\n",
        "    d : float : Cohen's d, the standardized mean difference between two groups\n",
        "    \"\"\"\n",
        "    # Calculate pooled standard deviation (S_within)\n",
        "    s_within = math.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
        "    # Calculate Cohen's d\n",
        "    d = (y2 - y1) / s_within\n",
        "    var = ((n1 + n2) / (n1*n2)) + (d**2 / (2 * (n1 + n2)))\n",
        "    return {\n",
        "      \"effect_size\": d,\n",
        "      \"variance\": var,\n",
        "      \"effect_size_type\": \"Cohen's d\"\n",
        "    }\n",
        "\n",
        "def mean_to_hedges_g(y1: float, y2: float, s1: float, s2: float, n1: int, n2: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Hedge's g and its variance using mean/sd for two independent groups.\n",
        "\n",
        "    Arguments:\n",
        "    y1 : float : Mean of the first group\n",
        "    y2 : float : Mean of the second group\n",
        "    s1 : float : Standard deviation of the first group\n",
        "    s2 : float : Standard deviation of the second group\n",
        "    n1 : int   : Sample size of the first group\n",
        "    n2 : int   : Sample size of the second group\n",
        "\n",
        "    Returns:\n",
        "    g : float : Hedge's g, the standardized mean difference between two groups\n",
        "    \"\"\"\n",
        "    s_within = math.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
        "    d = (y2 - y1) / s_within\n",
        "    var_d = ((n1 + n2) / (n1*n2)) + (d**2 / (2 * (n1 + n2)))\n",
        "\n",
        "    df = n1 + n2 - 2\n",
        "    J = 1 - (3 / (4 * df - 1))\n",
        "\n",
        "    g = J * d\n",
        "    var_g = J**2 * var_d\n",
        "    return {\n",
        "      \"effect_size\": g,\n",
        "      \"variance\": var_g,\n",
        "      \"effect_size_type\": \"Hedge's g\"\n",
        "    }\n",
        "\n",
        "def eta_squared_to_r(eta_squared: float, n: int) -> float:\n",
        "    \"\"\"\n",
        "    Convert eta-squared (η²) to Pearson's r.\n",
        "\n",
        "    Arguments:\n",
        "    eta_squared : float : Eta-squared value from ANOVA or other effect-size measures\n",
        "    n : int   : Total sample size\n",
        "\n",
        "    Returns:\n",
        "    r : float : Pearson's r, representing the proportion of variance explained by the predictor\n",
        "    \"\"\"\n",
        "    r = math.sqrt(eta_squared)\n",
        "    var_r = (1 - r**2)**2 / (n - 1)\n",
        "    return {\n",
        "      \"effect_size\": r,\n",
        "      \"variance\": var_r,\n",
        "      \"effect_size_type\": \"Pearson's r\"\n",
        "    }\n",
        "\n",
        "def t_statistic_to_cohens_d(t_value: float, n1: int, n2: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Cohen's d using the t-test statistic for two independent samples.\n",
        "\n",
        "    Arguments:\n",
        "    t_value : float : t-test statistic representing the standardized difference between two groups\n",
        "    n1 : int : Sample size of the first group\n",
        "    n2 : int : Sample size of the second group\n",
        "\n",
        "    Returns:\n",
        "    d : float : Cohen's d, the standardized mean difference between two groups\n",
        "    \"\"\"\n",
        "    d = t_value * math.sqrt((n1 + n2) / (n1 * n2))\n",
        "    var_d = ((n1 + n2) / (n1*n2)) + (d**2 / (2 * (n1 + n2)))\n",
        "\n",
        "    df = n1 + n2 - 2\n",
        "    J = 1 - (3 / (4 * df - 1))\n",
        "\n",
        "    g = J * d\n",
        "    var_g = J**2 * var_d\n",
        "    return {\n",
        "      \"effect_size\": g,\n",
        "      \"variance\": var_g,\n",
        "      \"effect_size_type\": \"Pearson's r\"\n",
        "    }\n",
        "\n",
        "def tau_to_r(tau: float, n: int) -> float:\n",
        "    \"\"\"\n",
        "    Convert the Spearman's rank correlation coefficient (τ) to Pearson's r.\n",
        "\n",
        "    Arguments:\n",
        "    tau : float : Spearman's rank correlation coefficient\n",
        "\n",
        "    Returns:\n",
        "    r : float : Pearson's r, representing the proportion of variance explained by the predictor\n",
        "    \"\"\"\n",
        "    r = math.sin(math.pi*tau/2)\n",
        "    var_r = (1 - r**2)**2 / (n - 1)\n",
        "    return {\n",
        "      \"effect_size\": r,\n",
        "      \"variance\": var_r,\n",
        "      \"effect_size_type\": \"Pearson's r\"\n",
        "    }\n",
        "\n",
        "# define a ReAct agent for coding\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "# formating outputs\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel\n",
        "from typing import Literal, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "import json\n",
        "\n",
        "# output format\n",
        "class ExtractedInfo(BaseModel):\n",
        "    effect_size: float = Field(..., description=\"Effect size value\")\n",
        "    variance: float = Field(..., description=\"Sampling variance of the effect size\")\n",
        "    direction: Literal[\"positive\", \"negative\"] = Field(..., description=\"Sign of the age effect\")\n",
        "    effect_size_type: Literal[\"Cohen's d\", \"Pearson's r\"] = Field(..., description=\"Metric type\")\n",
        "\n",
        "class EffectSizeAgent:\n",
        "    def __init__(self):\n",
        "      self.llm = OpenAI(model=\"gpt-4o\",api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "      self.agent = None\n",
        "      self.parser = PydanticOutputParser(ExtractedInfo)\n",
        "\n",
        "    def setup_function_tools(self):\n",
        "      \"\"\"\n",
        "      Provide a set of functions for calculating the effect size.\n",
        "      \"\"\"\n",
        "      calculation_tool_list = [\n",
        "            FunctionTool.from_defaults(fn=mean_to_hedges_g),\n",
        "            FunctionTool.from_defaults(fn=eta_squared_to_r),\n",
        "            FunctionTool.from_defaults(fn=t_statistic_to_cohens_d),\n",
        "            FunctionTool.from_defaults(fn=tau_to_r)\n",
        "        ]\n",
        "      return calculation_tool_list\n",
        "\n",
        "    def setup_query_tools(self):\n",
        "      \"\"\"\n",
        "      Load the vectorbase of the target paper. If no record is found, create the vectorbase.\n",
        "      \"\"\"\n",
        "      dataset_path = \"hub://junsonglu/metaLLM_lu2023\"\n",
        "      vector_store = DeepLakeVectorStore(dataset_path=dataset_path, read_only=True)\n",
        "      index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "\n",
        "      # Create query engine with metadata filter\n",
        "      query_engine = index.as_query_engine(\n",
        "          similarity_top_k=5,\n",
        "          llm=self.llm,\n",
        "          #filters={\"file_name\": file_name}\n",
        "          )\n",
        "\n",
        "      query_tool = QueryEngineTool.from_defaults(\n",
        "              query_engine,\n",
        "              name=\"full text of the paper\",\n",
        "              description=\"A RAG engine with the full text of the paper from which statistics are extracted from.\",\n",
        "      )\n",
        "\n",
        "      return query_tool\n",
        "\n",
        "    def initialize_agent(self):\n",
        "      context = \"\"\"\n",
        "      You are an expert research assistant specializing in psychology and meta-analysis.\n",
        "      Your task is to calculate effect sizes of the age effect on delay discounting from available statistics.\n",
        "\n",
        "      When you are completely done, produce the final result in this exact form:\n",
        "      {\n",
        "        \"effect_size\": <float>,\n",
        "        \"variance\": <float>,\n",
        "        \"direction\": \"positive\" | \"negative\",\n",
        "        \"effect_size_type\": \"Cohen's d\" | \"Pearson's r\"\n",
        "      }\n",
        "\n",
        "      Rules for the final answer:\n",
        "      - The JSON must be valid and parseable by json.loads.\n",
        "      - No extra commentary after Final Answer.\n",
        "      - \"direction\" is \"negative\" if higher age = less discounting; otherwise \"positive\".\n",
        "      \"\"\"\n",
        "      function_tools = self.setup_function_tools()\n",
        "      #query_tools = self.setup_query_tools()\n",
        "      all_tools = function_tools #+ [query_tools]\n",
        "\n",
        "      self.agent = ReActAgent.from_tools(\n",
        "          all_tools,\n",
        "          llm=self.llm,\n",
        "          max_iterations=5,\n",
        "          #output_parser=self.parser, # force to produce JSON\n",
        "          context=context,\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "    def extract_effect_size(self, stats):\n",
        "      prompt = \"\"\"\n",
        "      Please check the available statistics and its context:\n",
        "      {stats}.\n",
        "\n",
        "      Based on the statistics and context:\n",
        "      1. Decide which effect size metric to use, Cohen's d or Pearson's r. If mean/sd, t, and F statistics are available, calculate Cohen's d.\n",
        "      If eta squared is available, calculate Pearson's r correlation.\n",
        "      2. Calculate the effect size using the available functions and determine its sign, with a negative effect indicating older age associated with less discounting.\n",
        "      3. If the statistics are insufficient to use any available functions (e.g., the sample size for one group is missing), consult the original paper.\n",
        "      \"\"\"\n",
        "      response = self.agent.chat(prompt.format(stats=stats))\n",
        "      return response\n"
      ],
      "metadata": {
        "id": "KLML2xWYjbs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a9874a7d-ed45-4389-c97a-6ce4141a56de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_index.vector_stores'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-278792375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReActAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_stores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeeplake\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepLakeVectorStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;31m# formating outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPydanticOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.vector_stores'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializa the agent\n",
        "ESagent = EffectSizeAgent()\n",
        "ESagent.initialize_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4xE4DiCz8Ul",
        "outputId": "94a97ebc-8c79-48d1-bcfc-dc1299b3edf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.core.agent.react.formatter:ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_list = [\"1. **Effect Context**: Young adults showed a decrease in delay discounting with age.\\n   - **Reported Statistics**: Kendall's tau = -0.23, p = 0.005, n = 84\",\n",
        " \"2. **Effect Context**: Older adults showed an increase in delay discounting with age.\\n   - **Reported Statistics**: Kendall's tau = 0.15, p = 0.051, n = 104\",\n",
        " \"3. **Effect Context**: Physical age showed a stronger association with delay discounting for young adults.\\n   - **Reported Statistics**: Kendall's tau = -0.27, p = 0.001, n = 84\",\n",
        " \"4. **Effect Context**: Physical age showed a stronger association with delay discounting for older adults.\\n   - **Reported Statistics**: Kendall's tau = 0.17, p = 0.028, n = 104\",\n",
        " \"5. **Effect Context**: No significant association between chronological age and delay discounting in the middle-aged group.\\n   - **Reported Statistics**: Kendall's tau = -0.03, p = 0.78, n = 54\",\n",
        " \"6. **Effect Context**: Life history strategy negatively associated with delay discounting across all ages.\\n   - **Reported Statistics**: Kendall's tau = -0.15, p = 0.002, n = 242\\n\\nThese statistics provide insights into the age-related effects on delay discounting, allowing for the calculation of effect sizes such as Cohen's d or Pearson's r where applicable.\"]"
      ],
      "metadata": {
        "id": "D-QZ-d0u0Ta9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flags = [True, True, False, False, True, False]\n",
        "es_list_filtered = [es for idx, es in enumerate(es_list) if flags[idx]]"
      ],
      "metadata": {
        "id": "DZ3v-_6q0a_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code effect sizes\n",
        "es_code = ESagent.extract_effect_size(es_list_filtered[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ7vfJr10JG8",
        "outputId": "b753d995-892d-4b56-a6a1-4b553854d7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 784a7330-98ca-4329-847e-ab39cb5466df. Step input: \n",
            "      Please check the available statistics and its context:\n",
            "      2. **Effect Context**: Older adults showed an increase in delay discounting with age.\n",
            "   - **Reported Statistics**: Kendall's tau = 0.15, p = 0.051, n = 104.\n",
            "\n",
            "      Based on the statistics and context:\n",
            "      1. Decide which effect size metric to use, Cohen's d or Pearson's r. If mean/sd, t, and F statistics are available, calculate Cohen's d.\n",
            "      If eta squared is available, calculate Pearson's r correlation.\n",
            "      2. Calculate the effect size using the available functions and determine its sign, with a negative effect indicating older age associated with less discounting.\n",
            "      3. If the statistics are insufficient to use any available functions (e.g., the sample size for one group is missing), consult the original paper.\n",
            "      \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question. The reported statistic is Kendall's tau, which can be converted to Pearson's r. Therefore, I will use the tau_to_r tool.\n",
            "Action: tau_to_r\n",
            "Action Input: {'tau': 0.15, 'n': 104}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'effect_size': 0.2334453638559054, 'variance': 0.008679382705152843, 'effect_size_type': \"Pearson's r\"}\n",
            "\u001b[0m> Running step 39851407-140a-410a-97de-15ecb7e295fb. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have obtained the effect size and its variance. The context indicates that older adults showed an increase in delay discounting with age, which means the direction is \"positive.\"\n",
            "Answer: {\n",
            "  \"effect_size\": 0.2334453638559054,\n",
            "  \"variance\": 0.008679382705152843,\n",
            "  \"direction\": \"positive\",\n",
            "  \"effect_size_type\": \"Pearson's r\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(es_code.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JtS741D4BbD",
        "outputId": "595474ca-edc2-4063-d750-3e5d2322f932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"effect_size\": 0.2334453638559054,\n",
            "  \"variance\": 0.008679382705152843,\n",
            "  \"direction\": \"positive\",\n",
            "  \"effect_size_type\": \"Pearson's r\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code all effect sizes\n",
        "es_results = []\n",
        "\n",
        "for i, stats in enumerate(es_list_filtered, start=1):\n",
        "  print(f\"Coding effect {i}/{len(es_list_filtered)} ...\")\n",
        "  try:\n",
        "      result = ESagent.extract_effect_size(stats)\n",
        "      es_results.append(result.response)\n",
        "  except Exception as e:\n",
        "      print(f\"Error at index {i}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvoz2zja-v-_",
        "outputId": "bc4e4bf9-e34d-4c27-e961-8ba931d82093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coding effect 1/3 ...\n",
            "> Running step b2af19f7-47ff-443a-a12e-1e3a681c83ea. Step input: \n",
            "      Please check the available statistics and its context:\n",
            "      1. **Effect Context**: Young adults showed a decrease in delay discounting with age.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.23, p = 0.005, n = 84.\n",
            "\n",
            "      Based on the statistics and context:\n",
            "      1. Decide which effect size metric to use, Cohen's d or Pearson's r. If mean/sd, t, and F statistics are available, calculate Cohen's d.\n",
            "      If eta squared is available, calculate Pearson's r correlation.\n",
            "      2. Calculate the effect size using the available functions and determine its sign, with a negative effect indicating older age associated with less discounting.\n",
            "      3. If the statistics are insufficient to use any available functions (e.g., the sample size for one group is missing), consult the original paper.\n",
            "      \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question. The reported statistic is Kendall's tau, so I will convert it to Pearson's r using the tau_to_r tool.\n",
            "Action: tau_to_r\n",
            "Action Input: {'tau': -0.23, 'n': 84}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'effect_size': -0.35347484377925714, 'variance': 0.009225568542298408, 'effect_size_type': \"Pearson's r\"}\n",
            "\u001b[0m> Running step ed4c3b50-3dea-411d-b808-af07b97623dc. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have obtained the effect size and its variance. Now, I need to determine the direction of the effect. Since the effect context indicates that young adults showed a decrease in delay discounting with age, and the calculated Pearson's r is negative, the direction is \"negative.\"\n",
            "Answer: {\n",
            "  \"effect_size\": -0.35347484377925714,\n",
            "  \"variance\": 0.009225568542298408,\n",
            "  \"direction\": \"negative\",\n",
            "  \"effect_size_type\": \"Pearson's r\"\n",
            "}\n",
            "\u001b[0mCoding effect 2/3 ...\n",
            "> Running step 73c7dfd7-ad99-483d-bbbb-1fa1754299d1. Step input: \n",
            "      Please check the available statistics and its context:\n",
            "      2. **Effect Context**: Older adults showed an increase in delay discounting with age.\n",
            "   - **Reported Statistics**: Kendall's tau = 0.15, p = 0.051, n = 104.\n",
            "\n",
            "      Based on the statistics and context:\n",
            "      1. Decide which effect size metric to use, Cohen's d or Pearson's r. If mean/sd, t, and F statistics are available, calculate Cohen's d.\n",
            "      If eta squared is available, calculate Pearson's r correlation.\n",
            "      2. Calculate the effect size using the available functions and determine its sign, with a negative effect indicating older age associated with less discounting.\n",
            "      3. If the statistics are insufficient to use any available functions (e.g., the sample size for one group is missing), consult the original paper.\n",
            "      \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question. The reported statistic is Kendall's tau, so I will convert it to Pearson's r.\n",
            "Action: tau_to_r\n",
            "Action Input: {'tau': 0.15, 'n': 104}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'effect_size': 0.2334453638559054, 'variance': 0.008679382705152843, 'effect_size_type': \"Pearson's r\"}\n",
            "\u001b[0m> Running step a27e767b-3f47-47b7-8bb9-a53a143e1260. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have obtained the effect size and variance. Based on the context, the direction is \"positive\" because older adults showed an increase in delay discounting with age.\n",
            "Answer: {\n",
            "  \"effect_size\": 0.2334453638559054,\n",
            "  \"variance\": 0.008679382705152843,\n",
            "  \"direction\": \"positive\",\n",
            "  \"effect_size_type\": \"Pearson's r\"\n",
            "}\n",
            "\u001b[0mCoding effect 3/3 ...\n",
            "> Running step ead1677a-bd2a-4dbe-8e00-7ccd7f71673c. Step input: \n",
            "      Please check the available statistics and its context:\n",
            "      5. **Effect Context**: No significant association between chronological age and delay discounting in the middle-aged group.\n",
            "   - **Reported Statistics**: Kendall's tau = -0.03, p = 0.78, n = 54.\n",
            "\n",
            "      Based on the statistics and context:\n",
            "      1. Decide which effect size metric to use, Cohen's d or Pearson's r. If mean/sd, t, and F statistics are available, calculate Cohen's d.\n",
            "      If eta squared is available, calculate Pearson's r correlation.\n",
            "      2. Calculate the effect size using the available functions and determine its sign, with a negative effect indicating older age associated with less discounting.\n",
            "      3. If the statistics are insufficient to use any available functions (e.g., the sample size for one group is missing), consult the original paper.\n",
            "      \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question. The reported statistic is Kendall's tau, so I will convert it to Pearson's r.\n",
            "Action: tau_to_r\n",
            "Action Input: {'tau': -0.03, 'n': 54}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'effect_size': -0.04710645070964266, 'variance': 0.018784280917785397, 'effect_size_type': \"Pearson's r\"}\n",
            "\u001b[0m> Running step 28025422-5ba9-4452-847b-7c20cc3b4c74. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
            "Answer: {\n",
            "  \"effect_size\": -0.04710645070964266,\n",
            "  \"variance\": 0.018784280917785397,\n",
            "  \"direction\": \"negative\",\n",
            "  \"effect_size_type\": \"Pearson's r\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxlI29sc_6nm",
        "outputId": "edb2f9a7-27e3-4376-fe14-7b52e8e16b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{\\n  \"effect_size\": -0.35347484377925714,\\n  \"variance\": 0.009225568542298408,\\n  \"direction\": \"negative\",\\n  \"effect_size_type\": \"Pearson\\'s r\"\\n}',\n",
              " '{\\n  \"effect_size\": 0.2334453638559054,\\n  \"variance\": 0.008679382705152843,\\n  \"direction\": \"positive\",\\n  \"effect_size_type\": \"Pearson\\'s r\"\\n}',\n",
              " '{\\n  \"effect_size\": -0.04710645070964266,\\n  \"variance\": 0.018784280917785397,\\n  \"direction\": \"negative\",\\n  \"effect_size_type\": \"Pearson\\'s r\"\\n}']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3: Iterative Retrieval"
      ],
      "metadata": {
        "id": "8kYFk6HNG1UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load OCR-extracted papers\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "doc_names = os.listdir('./data/lu_2023_include_OCR_Mistral')\n",
        "document = SimpleDirectoryReader(input_files=[\"./data/lu_2023_include_OCR_Mistral/Mok et al_2020_Is it time.md\"]).load_data()\n",
        "\n",
        "safe_name = \"Mok_et_al_2020_Is_it_time\"\n",
        "persist_dir_vec = f\"./data/storage_psychbull/{safe_name}\"\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(document)\n",
        "summary_index = SummaryIndex.from_documents(document)\n"
      ],
      "metadata": {
        "id": "3pD6XpMKVp0K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the indices\n",
        "vector_index.storage_context.persist(persist_dir=persist_dir_vec)\n",
        "summary_index.storage_context.persist(persist_dir=persist_dir_vec)"
      ],
      "metadata": {
        "id": "bWDjinV4am1k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools and Test"
      ],
      "metadata": {
        "id": "DjXpqdj5XG5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create related tools\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "# for summarizing the paper structure\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "  response_mode=\"tree_summarize\",\n",
        "  use_async=True,\n",
        ")\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "  query_engine=summary_query_engine,\n",
        "  description=(\n",
        "    \"Useful for summarizing the paper structure.\"\n",
        "  ),\n",
        ")\n",
        "\n",
        "# for retrieval\n",
        "vector_query_engine = vector_index.as_query_engine()\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "  query_engine=vector_query_engine,\n",
        "  description=(\n",
        "    \"Useful for retrieving specific context from the paper.\"\n",
        "  ),\n",
        ")\n",
        "\n",
        "# selector\n",
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# for coding the moderator \"Delay_Length_Min\" and \"Delay_Length_Max\"\n",
        "def analyze_delay_range(values):\n",
        "  \"\"\"\n",
        "  Compute min and max delay length in the delay discounting task.\n",
        "  Input: a list of numbers (e.g., [1, 5, 10])\n",
        "  Output: a dict with 'Delay_Length_Min' and 'Delay_Length_Max'.\n",
        "  \"\"\"\n",
        "  if not values:\n",
        "      return {\"Delay_Length_Min\": None, \"Delay_Length_Max\": None}\n",
        "\n",
        "  return {\n",
        "      \"Delay_Length_Min\": min(values),\n",
        "      \"Delay_Length_Max\": max(values)\n",
        "  }"
      ],
      "metadata": {
        "id": "ezDrpdjeG4v2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the structure of the paper?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkKz1cMf9-6",
        "outputId": "29b02b45-243a-4bd0-a392-113a970a6081"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarizing the paper structure..\n",
            "\u001b[0mThe paper is structured into two experiments. Experiment 1 examines the effects of personally relevant cues associated with delayed rewards on discounting behavior in young and older adults. Experiment 2 investigates the impact of personal cues on risky decision-making in a probability discounting task. The general discussion section provides an overview of the findings from both experiments, discussing age-related differences in discounting behavior, the influence of episodic cues on decision-making, and the implications for understanding intertemporal choice and risky decision-making. The paper covers various topics such as age-related differences in delay discounting, the effects of personally relevant cues on decision-making tasks, the relationship between delay and probability discounting, the role of different brain regions in decision-making, and potential interventions to enhance decision-making across different age groups.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentic Retrieval Augmented Generation"
      ],
      "metadata": {
        "id": "0zmnX8QfnXm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define ES functions\n",
        "import math\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
        "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, FilterOperator\n",
        "\n",
        "# define a ReAct agent for coding\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "class delayAgent:\n",
        "    def __init__(self):\n",
        "      self.llm = OpenAI(model=\"gpt-4o\",api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "      self.agent = None\n",
        "\n",
        "    def setup_function_tools(self):\n",
        "      \"\"\"\n",
        "      Provide a set of functions for deriving the moderator.\n",
        "      \"\"\"\n",
        "      calculation_tool_list = [\n",
        "            FunctionTool.from_defaults(fn=analyze_delay_range,\n",
        "            name=\"analyze_delay_range\",\n",
        "            description=\"Compute min and max delay lengths in a list of numbers.\",\n",
        "            return_direct=True),\n",
        "\n",
        "        ]\n",
        "      return calculation_tool_list\n",
        "\n",
        "    def setup_query_tools(self):\n",
        "      \"\"\"\n",
        "      Load the vectorbase of the target paper.\n",
        "      \"\"\"\n",
        "\n",
        "      # for summary\n",
        "      summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "      )\n",
        "\n",
        "      summary_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=summary_query_engine,\n",
        "        name=\"summary_query\",\n",
        "        description=(\n",
        "          \"Useful for summarizing the paper structure.\"\n",
        "        ),\n",
        "      )\n",
        "\n",
        "      # for retrieval\n",
        "      vector_query_engine = vector_index.as_query_engine(\n",
        "          similarity_top_k=5,\n",
        "      )\n",
        "      vector_tool = QueryEngineTool.from_defaults(\n",
        "          query_engine=vector_query_engine,\n",
        "          name=\"vector_query\",\n",
        "          description=(\n",
        "            \"Useful for retrieving specific context from the paper.\"\n",
        "          ),\n",
        "      )\n",
        "\n",
        "      return [summary_tool, vector_tool]\n",
        "\n",
        "    def initialize_agent(self):\n",
        "      context = \"\"\"\n",
        "      You are an expert research assistant for psychology meta-analysis.\n",
        "      Task: For each study in the paper, identify the delay lengths used in the delay-discounting tasks.\n",
        "      Procedure:\n",
        "      1) Summarize paper structure and number of studies using the summary query engine.\n",
        "      2) Retrieve method sections for each study to identify delay lengths using query engines. If other metrics like weeks or years are used, convert into days.\n",
        "      3) Use available function(s) to compute Delay_Length_Min and Delay_Length_Max for each study.\n",
        "      \"\"\"\n",
        "      function_tools = self.setup_function_tools()\n",
        "      query_tools = self.setup_query_tools()\n",
        "      all_tools = function_tools + query_tools\n",
        "\n",
        "      self.agent = ReActAgent.from_tools(\n",
        "          all_tools,\n",
        "          llm=self.llm,\n",
        "          max_iterations=10,\n",
        "          context=context,\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "    def extract_moderators(self):\n",
        "      \"\"\"\n",
        "      Run the agent to extract moderator information.\n",
        "      \"\"\"\n",
        "      if self.agent is None:\n",
        "        self.initialize_agent()\n",
        "\n",
        "      query = (\n",
        "          \"Extract all delay lengths in days (minimum and maximum) used in the \"\n",
        "          \"delay discounting tasks across all studies in this paper. \"\n",
        "      )\n",
        "\n",
        "      try:\n",
        "        response = self.agent.chat(query)\n",
        "        return response\n",
        "      except Exception as e:\n",
        "        print(f\"Error during extraction: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ilxnHxljPAHT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the moderator\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "agent_sep_engine = delayAgent()\n",
        "result_sep_engine = agent_sep_engine.extract_moderators()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOI3XobF6ds5",
        "outputId": "8a886e70-9389-49a1-c830-c930dabf6820"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.core.agent.react.formatter:ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step dcb6b352-9978-43e4-a28d-5c8b815cfb1d. Step input: Extract all delay lengths in days (minimum and maximum) used in the delay discounting tasks across all studies in this paper. \n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question by first summarizing the paper structure to identify the number of studies.\n",
            "Action: summary_query\n",
            "Action Input: {'input': 'Summarize the structure of the paper and identify the number of studies included.'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: The paper is structured around two experiments. Experiment 1 focuses on delay discounting, while Experiment 2 examines probability discounting. These studies investigate the effects of personally relevant cues on decision-making processes in young and older adults. The paper includes a total of two studies: one on delay discounting and the other on probability discounting.\n",
            "\u001b[0m> Running step 007a0108-5687-4254-86d5-3b365d5338da. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The paper includes two experiments, but only Experiment 1 is relevant to delay discounting. I need to retrieve the method section for Experiment 1 to identify the delay lengths used in the delay-discounting tasks.\n",
            "Action: vector_query\n",
            "Action Input: {'input': 'Retrieve the method section for Experiment 1 focusing on delay discounting to identify delay lengths.'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Participants completed a computerized delay discounting task where they were asked to choose between smaller, immediate reward amounts and larger, delayed reward amounts at seven delays: waiting 1 week, 1 month, 3 months, 6 months, 1 year, 3 years, and 10 years before receiving the reward.\n",
            "\u001b[0m> Running step 7fe884ea-7fd8-462a-85a4-bbb2bdae4976. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have identified the delay lengths used in Experiment 1. I need to convert these delays into days and then compute the minimum and maximum delay lengths.\n",
            "\n",
            "- 1 week = 7 days\n",
            "- 1 month = 30 days (assuming an average month)\n",
            "- 3 months = 90 days\n",
            "- 6 months = 180 days\n",
            "- 1 year = 365 days\n",
            "- 3 years = 1095 days\n",
            "- 10 years = 3650 days\n",
            "\n",
            "Now, I will compute the minimum and maximum delay lengths using these values.\n",
            "Action: analyze_delay_range\n",
            "Action Input: {'values': [7, 30, 90, 180, 365, 1095, 3650]}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'Delay_Length_Min': 7, 'Delay_Length_Max': 3650}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_sep_engine.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w92ScuU8LGc",
        "outputId": "a989c42e-5cf1-4a22-e0bb-6aa75df37f63"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Delay_Length_Min': 7, 'Delay_Length_Max': 3650}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}